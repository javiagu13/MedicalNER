{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "medNer.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KtXs8Ygnbpch",
        "outputId": "682932ff-f5bc-4db0-de6e-4e1d0a3c8947"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b7oMcQ97Uxnr"
      },
      "source": [
        "###IMPORTANT-> DO NOT RUN THIS PART UNLESS YOU WANT TO CREATE NEW TRAINING TEST AND DEV DATASETS."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P7fcxPapDf1e"
      },
      "source": [
        "### CREATING TEST, TRAIN AND DEV FROM MEDMENTIONS CORPUS"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ipuAjaI5CZ1C"
      },
      "source": [
        "READING FILES: dev, test, train and corpus"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u8i4hMnkb6U1"
      },
      "source": [
        "#read file DEV\n",
        "devTxt=\"/content/drive/MyDrive/medNer/corpus_pubtator_pmids_dev.txt\"\n",
        "with open(devTxt, \"r\") as file1:\n",
        "    devTxtList = file1.readlines()\n",
        "#delete \\n at the end of every line    \n",
        "for i in range(0,len(devTxtList)):\n",
        "  devTxtList[i]=devTxtList[i].split('\\n')[0]\n",
        "\n",
        "\n",
        "#read file TEST\n",
        "testTxt=\"/content/drive/MyDrive/medNer/corpus_pubtator_pmids_test.txt\"\n",
        "with open(testTxt, \"r\") as file2:\n",
        "    testTxtList = file2.readlines()\n",
        "#delete \\n at the end of every line    \n",
        "for i in range(0,len(testTxtList)):\n",
        "  testTxtList[i]=testTxtList[i].split('\\n')[0]\n",
        "\n",
        "\n",
        "#read file TRAIN\n",
        "trngTxt=\"/content/drive/MyDrive/medNer/corpus_pubtator_pmids_trng.txt\"\n",
        "with open(trngTxt, \"r\") as file3:\n",
        "    trngTxtList = file3.readlines()\n",
        "#delete \\n at the end of every line    \n",
        "for i in range(0,len(trngTxtList)):\n",
        "  trngTxtList[i]=trngTxtList[i].split('\\n')[0]\n",
        "\n",
        "\n",
        "#read file CORPUS\n",
        "corpusTxt=\"/content/drive/MyDrive/medNer/corpus_pubtator.txt\"\n",
        "with open(corpusTxt, \"r\") as file4:\n",
        "    corpusTxtList = file4.readlines()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Inr-XM4KmEzd"
      },
      "source": [
        "LOADING TOKENIZER"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "blqFT1nkIWjV"
      },
      "source": [
        "# http://sentiment.christopherpotts.net/code-data/happyfuntokenizing.py -en bertsio motza\n",
        "import nltk, re, json\n",
        "import spacy\n",
        "from collections import Counter\n",
        "\n",
        "# Erabiltzaile-izenak batera mantendu (@ ikurraz hasitako edozein token, eta ondoren A-Z, a-z, 0-9)\n",
        "regexes=(\n",
        "# zuriunea ez den beste edozer\n",
        "r\"(?:\\w+\\.\\w+)\", \n",
        "#symbols\n",
        "r\"(?:[\\<\\>\\=\\+|\\-|\\/|\\*\\\\\\'\\\"|\\%|\\w]+)\",   \n",
        "# hashtag-ak elkarrekin mantendu (# ikurraz hasitako edozein token, eta ondoren A-Z, a-z, 0-9, _, edo -)\n",
        "r\"(?:\\#+[\\w_]+[\\w\\'_\\-]*[\\w_]+)\",\n",
        "\n",
        "\n",
        ")\n",
        "\n",
        "big_regex=\"|\".join(regexes)\n",
        "\n",
        "my_extensible_tokenizer = re.compile(big_regex, re.VERBOSE | re.I | re.UNICODE)\n",
        "\n",
        "def my_extensible_tokenize(text):\n",
        "    return my_extensible_tokenizer.findall(text)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z_0jKf0RCxDu"
      },
      "source": [
        "CREATING A FUNCTION TO NORMALIZE ANY STRING USING THE TOKENIZER"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P1MdXkSXLGtT"
      },
      "source": [
        "def normalizeString(string):\n",
        "  #print(string)\n",
        "  last_char = string[-1]\n",
        "  isEndOrComma=None\n",
        "\n",
        "  if last_char == '.':\n",
        "    isEndOrComma=\"END\"\n",
        "  if last_char == ',':\n",
        "    isEndOrComma=\"COMMA\"\n",
        "    \n",
        "  string=my_extensible_tokenize(string)\n",
        "  #print(string)\n",
        "  if len(string)==0:\n",
        "    return \"\", isEndOrComma\n",
        "  else:\n",
        "    return string[0], isEndOrComma"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3hgG1mKFId0I",
        "outputId": "f7a1f21f-14a6-4a82-c1ef-52ce6e000faa"
      },
      "source": [
        "normalizeString(\"(hola,)\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('hola', None)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1zV8s4Rdh0BL"
      },
      "source": [
        "CREATING FUNCTIONS FOR CREATING TSV FILES FOR TRAINING DEV AND TEST"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "lizzgEu_rmD1"
      },
      "source": [
        "import csv\n",
        "\n",
        "def textToTokens(title, paper):\n",
        "  title=title.split()\n",
        "  paper=paper.split()\n",
        "  title[0]=title[0].split('|t|')[1]\n",
        "  paper[0]=paper[0].split('|a|')[1]\n",
        "  text = title+paper\n",
        "  #print(text)\n",
        "  return text\n",
        "  \n",
        "def textAndBItoTSV(tsv_writer, text, BI):#\n",
        "\n",
        "  textCount=0\n",
        "  for i in BI:\n",
        "    word = i.split()\n",
        "    #print(word[0])\n",
        "    #print(text[textCount])\n",
        "    for w in range(0,len(word)):\n",
        "      #print(\"for\")\n",
        "      if textCount<len(text): #puede que sea <=\n",
        "\n",
        "        #normalize strings\n",
        "        #print(\"word[w]\"+str(word[w]))\n",
        "        word[w], isEndOrComma=normalizeString(word[w])\n",
        "        #print(\"text[textCount\"+str(textCount)+\"]\"+str(text[textCount]))\n",
        "        text[textCount], isEndOrComma=normalizeString(text[textCount])\n",
        "\n",
        "        if word[w]==text[textCount]:\n",
        "          if w==0:\n",
        "            #print(word[w])\n",
        "            #print(text[textCount])\n",
        "            if word[w]!=\"\" and text[textCount]!=\"\":\n",
        "              tsv_writer.writerow([text[textCount].lower(), 'B-MED'])\n",
        "              #print(\"B\")\n",
        "              #print(\"word: \"+str(word[w]))\n",
        "              #print(\"textCount: \"+str(text[textCount]))\n",
        "              if isEndOrComma==\"END\":\n",
        "                tsv_writer.writerow([\".\", 'O'])\n",
        "                tsv_writer.writerow([\"\", ''])\n",
        "              if isEndOrComma==\"COMMA\":\n",
        "                tsv_writer.writerow([\",\", 'O'])\n",
        "\n",
        "            textCount+=1\n",
        "            \n",
        "          else:\n",
        "            if word[w]!=\"\" and text[textCount]!=\"\":\n",
        "              tsv_writer.writerow([text[textCount].lower(), 'I-MED'])\n",
        "              #print(\"I\")\n",
        "              #print(\"word: \"+str(word[w]))\n",
        "              #print(\"textCount: \"+str(text[textCount]))\n",
        "              if isEndOrComma==\"END\":\n",
        "                tsv_writer.writerow([\".\", 'O'])\n",
        "                tsv_writer.writerow([\"\", ''])\n",
        "              if isEndOrComma==\"COMMA\":\n",
        "                tsv_writer.writerow([\",\", 'O'])\n",
        "            textCount+=1\n",
        "            \n",
        "        else:\n",
        "          justEntered=True\n",
        "          while textCount<len(text)-1:\n",
        "            #print(\"while\")\n",
        "            if justEntered==False:\n",
        "              #print(\"word[w]\"+str(word[w]))\n",
        "              word[w], isEndOrComma=normalizeString(word[w])\n",
        "              #print(normalizeString(text[textCount]))\n",
        "              #print(\"text[textCount\"+str(textCount)+\"]\"+str(text[textCount]))\n",
        "              text[textCount], isEndOrComma=normalizeString(text[textCount])\n",
        "            justEntered=False\n",
        "            if word[w]!=text[textCount]:\n",
        "              if word[w]!=\"\" and text[textCount]!=\"\":\n",
        "                tsv_writer.writerow([text[textCount].lower(), 'O'])\n",
        "                if isEndOrComma==\"END\":\n",
        "                  tsv_writer.writerow([\".\", 'O'])\n",
        "                  tsv_writer.writerow([\"\", ''])\n",
        "                if isEndOrComma==\"COMMA\":\n",
        "                  tsv_writer.writerow([\",\", 'O'])\n",
        "\n",
        "              #print(\"O\")\n",
        "              #print(\"word: \"+str(word[w]))\n",
        "              #print(\"textCount: \"+str(text[textCount]))\n",
        "              textCount+=1\n",
        "            else:\n",
        "              if w==0:\n",
        "                #print(\"B\")\n",
        "                #print(\"word: \"+str(word[w]))\n",
        "                #print(\"textCount: \"+str(text[textCount]))\n",
        "                if word[w]!=\"\" and text[textCount]!=\"\":\n",
        "                  tsv_writer.writerow([text[textCount].lower(), 'B-MED'])\n",
        "                  if isEndOrComma==\"END\":\n",
        "                    tsv_writer.writerow([\".\", 'O'])\n",
        "                    tsv_writer.writerow([\"\", ''])\n",
        "                  if isEndOrComma==\"COMMA\":\n",
        "                    tsv_writer.writerow([\",\", 'O'])\n",
        "                textCount+=1\n",
        "                break\n",
        "              else:\n",
        "                #print(\"I\")\n",
        "                #print(\"word: \"+str(word[w]))\n",
        "                #print(\"textCount: \"+str(text[textCount]))\n",
        "                if word[w]!=\"\" and text[textCount]!=\"\":\n",
        "                  tsv_writer.writerow([text[textCount].lower(), 'I-MED'])\n",
        "                  if isEndOrComma==\"END\":\n",
        "                    tsv_writer.writerow([\".\", 'O'])\n",
        "                    tsv_writer.writerow([\"\", ''])\n",
        "                  if isEndOrComma==\"COMMA\":\n",
        "                    tsv_writer.writerow([\",\", 'O'])\n",
        "                textCount+=1\n",
        "                break\n",
        "         \n",
        "        \n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "keeY43VSBSzw"
      },
      "source": [
        "CREATING TRAINING SET"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1d38I3Bpd0zU"
      },
      "source": [
        "inPaper=False\n",
        "titleRow=0\n",
        "paperRow=1\n",
        "BIbek=[]\n",
        "\n",
        "#COMMENT NEXT TWO LINES FOR WHOLE CORPUS\n",
        "#maxAmountOfPapers=800\n",
        "paperKont=0\n",
        "\n",
        "with open('/content/drive/MyDrive/medNer/medMentions-train.tsv', 'wt') as out_file:\n",
        "  tsv_writer = csv.writer(out_file, delimiter='\\t')\n",
        "\n",
        "  for i in range(0,len(corpusTxtList)):\n",
        "    \n",
        "    #beginning of paper\n",
        "    if(inPaper==False):\n",
        "      #number of paper\n",
        "      paperNumber=corpusTxtList[i+2].split('\\t')[0]\n",
        "      #title\n",
        "      currentTitle=corpusTxtList[i]\n",
        "      #paper\n",
        "      currentPaper=corpusTxtList[i+1]\n",
        "      #restarting BIbek\n",
        "      \n",
        "\n",
        "    #mid paper\n",
        "    if titleRow!=i and paperRow!=i and corpusTxtList[i]!='\\n':\n",
        "      #vector for storing begin and inside words\n",
        "      BIbek.append(corpusTxtList[i].split('\\t')[3])\n",
        "    inPaper=True\n",
        "    #end of paper\n",
        "    if corpusTxtList[i]=='\\n':\n",
        "      titleRow=i+1\n",
        "      paperRow=i+2\n",
        "      inPaper=False\n",
        "      if paperNumber in trngTxtList:\n",
        "        #COMMENT NEXT LINE FOR WHOLE CORPUS\n",
        "        #if paperKont<maxAmountOfPapers:\n",
        "          textAndBItoTSV(tsv_writer, textToTokens(currentTitle, currentPaper),BIbek)\n",
        "          #COMMENT NEXT LINE FOR WHOLE CORPUS\n",
        "          #paperKont+=1\n",
        "      BIbek=[]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kwioBaAuDCOR"
      },
      "source": [
        "CREATING TEST SET"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M7Qryto1C4AH"
      },
      "source": [
        "inPaper=False\n",
        "titleRow=0\n",
        "paperRow=1\n",
        "BIbek=[]\n",
        "\n",
        "#COMMENT NEXT TWO LINES FOR WHOLE CORPUS\n",
        "#maxAmountOfPapers=320\n",
        "paperKont=0\n",
        "\n",
        "with open('/content/drive/MyDrive/medNer/medMentions-test.tsv', 'wt') as out_file:\n",
        "  tsv_writer = csv.writer(out_file, delimiter='\\t')\n",
        "\n",
        "  for i in range(0,len(corpusTxtList)):\n",
        "    \n",
        "    #beginning of paper\n",
        "    if(inPaper==False):\n",
        "      #number of paper\n",
        "      paperNumber=corpusTxtList[i+2].split('\\t')[0]\n",
        "      #title\n",
        "      currentTitle=corpusTxtList[i]\n",
        "      #paper\n",
        "      currentPaper=corpusTxtList[i+1]\n",
        "      #restarting BIbek\n",
        "      \n",
        "\n",
        "    #mid paper\n",
        "    if titleRow!=i and paperRow!=i and corpusTxtList[i]!='\\n':\n",
        "      #vector for storing begin and inside words\n",
        "      BIbek.append(corpusTxtList[i].split('\\t')[3])\n",
        "    inPaper=True\n",
        "    #end of paper\n",
        "    if corpusTxtList[i]=='\\n':\n",
        "      titleRow=i+1\n",
        "      paperRow=i+2\n",
        "      inPaper=False\n",
        "      if paperNumber in testTxtList:\n",
        "        #COMMENT NEXT LINE FOR WHOLE CORPUS\n",
        "        #if paperKont<maxAmountOfPapers:\n",
        "          textAndBItoTSV(tsv_writer, textToTokens(currentTitle, currentPaper),BIbek)\n",
        "          #COMMENT NEXT LINE FOR WHOLE CORPUS\n",
        "          #paperKont+=1\n",
        "      BIbek=[]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ji2ErFC0DKfm"
      },
      "source": [
        "CREATING DEV SET"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RjoX586NDILu"
      },
      "source": [
        "inPaper=False\n",
        "titleRow=0\n",
        "paperRow=1\n",
        "BIbek=[]\n",
        "\n",
        "#COMMENT NEXT TWO LINES FOR WHOLE CORPUS\n",
        "#maxAmountOfPapers=320\n",
        "paperKont=0\n",
        "\n",
        "with open('/content/drive/MyDrive/medNer/medMentions-dev.tsv', 'wt') as out_file:\n",
        "  tsv_writer = csv.writer(out_file, delimiter='\\t')\n",
        "\n",
        "  for i in range(0,len(corpusTxtList)):\n",
        "    \n",
        "    #beginning of paper\n",
        "    if(inPaper==False):\n",
        "      #number of paper\n",
        "      paperNumber=corpusTxtList[i+2].split('\\t')[0]\n",
        "      #title\n",
        "      currentTitle=corpusTxtList[i]\n",
        "      #paper\n",
        "      currentPaper=corpusTxtList[i+1]\n",
        "      #restarting BIbek\n",
        "      \n",
        "\n",
        "    #mid paper\n",
        "    if titleRow!=i and paperRow!=i and corpusTxtList[i]!='\\n':\n",
        "      #vector for storing begin and inside words\n",
        "      BIbek.append(corpusTxtList[i].split('\\t')[3])\n",
        "    inPaper=True\n",
        "    #end of paper\n",
        "    if corpusTxtList[i]=='\\n':\n",
        "      titleRow=i+1\n",
        "      paperRow=i+2\n",
        "      inPaper=False\n",
        "      if paperNumber in devTxtList:\n",
        "        #COMMENT NEXT LINE FOR WHOLE CORPUS\n",
        "        #if paperKont<maxAmountOfPapers:\n",
        "          textAndBItoTSV(tsv_writer, textToTokens(currentTitle, currentPaper),BIbek)\n",
        "          #COMMENT NEXT LINE FOR WHOLE CORPUS\n",
        "          #paperKont+=1\n",
        "\n",
        "      BIbek=[]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AUNqmWztVFQi"
      },
      "source": [
        "###YOU CAN TEST THE TRAINING PART IF YOU ARE WILLING TO TRAIN AN ALREADY EXISTING MODEL"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3QkUODUWOm5Z"
      },
      "source": [
        "###TRAINING"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dS45OK6FOpnZ"
      },
      "source": [
        "Flair "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-gUQIAesDPV2",
        "outputId": "589f0415-657d-4032-d2a8-a4ef71c6b5ef"
      },
      "source": [
        "pip install --upgrade flair"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting flair\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f0/3a/1b46a0220d6176b22bcb9336619d1731301bc2c75fa926a9ef953e6e4d58/flair-0.8.0.post1-py3-none-any.whl (284kB)\n",
            "\r\u001b[K     |█▏                              | 10kB 23.1MB/s eta 0:00:01\r\u001b[K     |██▎                             | 20kB 30.4MB/s eta 0:00:01\r\u001b[K     |███▌                            | 30kB 34.8MB/s eta 0:00:01\r\u001b[K     |████▋                           | 40kB 29.0MB/s eta 0:00:01\r\u001b[K     |█████▊                          | 51kB 31.0MB/s eta 0:00:01\r\u001b[K     |███████                         | 61kB 32.6MB/s eta 0:00:01\r\u001b[K     |████████                        | 71kB 34.4MB/s eta 0:00:01\r\u001b[K     |█████████▏                      | 81kB 29.7MB/s eta 0:00:01\r\u001b[K     |██████████▍                     | 92kB 30.8MB/s eta 0:00:01\r\u001b[K     |███████████▌                    | 102kB 31.6MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 112kB 31.6MB/s eta 0:00:01\r\u001b[K     |█████████████▉                  | 122kB 31.6MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 133kB 31.6MB/s eta 0:00:01\r\u001b[K     |████████████████                | 143kB 31.6MB/s eta 0:00:01\r\u001b[K     |█████████████████▎              | 153kB 31.6MB/s eta 0:00:01\r\u001b[K     |██████████████████▍             | 163kB 31.6MB/s eta 0:00:01\r\u001b[K     |███████████████████▋            | 174kB 31.6MB/s eta 0:00:01\r\u001b[K     |████████████████████▊           | 184kB 31.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████▉          | 194kB 31.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 204kB 31.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████▏       | 215kB 31.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▎      | 225kB 31.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 235kB 31.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▋    | 245kB 31.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▊   | 256kB 31.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 266kB 31.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 276kB 31.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 286kB 31.6MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: matplotlib>=2.2.3 in /usr/local/lib/python3.7/dist-packages (from flair) (3.2.2)\n",
            "Collecting transformers>=4.0.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d8/b2/57495b5309f09fa501866e225c84532d1fd89536ea62406b2181933fb418/transformers-4.5.1-py3-none-any.whl (2.1MB)\n",
            "\u001b[K     |████████████████████████████████| 2.1MB 51.7MB/s \n",
            "\u001b[?25hCollecting langdetect\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0e/72/a3add0e4eec4eb9e2569554f7c70f4a3c27712f40e3284d483e88094cc0e/langdetect-1.0.9.tar.gz (981kB)\n",
            "\u001b[K     |████████████████████████████████| 983kB 49.0MB/s \n",
            "\u001b[?25hCollecting konoha<5.0.0,>=4.0.0\n",
            "  Downloading https://files.pythonhosted.org/packages/02/be/4dd30d56a0a19619deb9bf41ba8202709fa83b1b301b876572cd6dc38117/konoha-4.6.4-py3-none-any.whl\n",
            "Collecting segtok>=1.5.7\n",
            "  Downloading https://files.pythonhosted.org/packages/41/08/582dab5f4b1d5ca23bc6927b4bb977c8ff7f3a87a3b98844ef833e2f5623/segtok-1.5.10.tar.gz\n",
            "Requirement already satisfied, skipping upgrade: scikit-learn>=0.21.3 in /usr/local/lib/python3.7/dist-packages (from flair) (0.22.2.post1)\n",
            "Collecting sqlitedict>=1.6.0\n",
            "  Downloading https://files.pythonhosted.org/packages/5c/2d/b1d99e9ad157dd7de9cd0d36a8a5876b13b55e4b75f7498bc96035fb4e96/sqlitedict-1.7.0.tar.gz\n",
            "Requirement already satisfied, skipping upgrade: hyperopt>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from flair) (0.1.2)\n",
            "Collecting deprecated>=1.2.4\n",
            "  Downloading https://files.pythonhosted.org/packages/fb/73/994edfcba74443146c84b91921fcc269374354118d4f452fb0c54c1cbb12/Deprecated-1.2.12-py2.py3-none-any.whl\n",
            "Collecting mpld3==0.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/91/95/a52d3a83d0a29ba0d6898f6727e9858fe7a43f6c2ce81a5fe7e05f0f4912/mpld3-0.3.tar.gz (788kB)\n",
            "\u001b[K     |████████████████████████████████| 798kB 42.3MB/s \n",
            "\u001b[?25hCollecting ftfy\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ce/b5/5da463f9c7823e0e575e9908d004e2af4b36efa8d02d3d6dad57094fcb11/ftfy-6.0.1.tar.gz (63kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 11.3MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: tqdm>=4.26.0 in /usr/local/lib/python3.7/dist-packages (from flair) (4.41.1)\n",
            "Collecting torch<=1.7.1,>=1.5.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/90/5d/095ddddc91c8a769a68c791c019c5793f9c4456a688ddd235d6670924ecb/torch-1.7.1-cp37-cp37m-manylinux1_x86_64.whl (776.8MB)\n",
            "\u001b[K     |████████████████████████████████| 776.8MB 22kB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: python-dateutil>=2.6.1 in /usr/local/lib/python3.7/dist-packages (from flair) (2.8.1)\n",
            "Collecting gdown==3.12.2\n",
            "  Downloading https://files.pythonhosted.org/packages/50/21/92c3cfe56f5c0647145c4b0083d0733dd4890a057eb100a8eeddf949ffe9/gdown-3.12.2.tar.gz\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting janome\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a8/63/98858cbead27df7536c7e300c169da0999e9704d02220dc6700b804eeff0/Janome-0.4.1-py2.py3-none-any.whl (19.7MB)\n",
            "\u001b[K     |████████████████████████████████| 19.7MB 46.2MB/s \n",
            "\u001b[?25hCollecting sentencepiece==0.1.95\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f5/99/e0808cb947ba10f575839c43e8fafc9cc44e4a7a2c8f79c60db48220a577/sentencepiece-0.1.95-cp37-cp37m-manylinux2014_x86_64.whl (1.2MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2MB 45.0MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: numpy<1.20.0 in /usr/local/lib/python3.7/dist-packages (from flair) (1.19.5)\n",
            "Requirement already satisfied, skipping upgrade: regex in /usr/local/lib/python3.7/dist-packages (from flair) (2019.12.20)\n",
            "Requirement already satisfied, skipping upgrade: tabulate in /usr/local/lib/python3.7/dist-packages (from flair) (0.8.9)\n",
            "Requirement already satisfied, skipping upgrade: gensim<=3.8.3,>=3.4.0 in /usr/local/lib/python3.7/dist-packages (from flair) (3.6.0)\n",
            "Collecting huggingface-hub\n",
            "  Downloading https://files.pythonhosted.org/packages/a1/88/7b1e45720ecf59c6c6737ff332f41c955963090a18e72acbcbeac6b25e86/huggingface_hub-0.0.8-py3-none-any.whl\n",
            "Requirement already satisfied, skipping upgrade: lxml in /usr/local/lib/python3.7/dist-packages (from flair) (4.2.6)\n",
            "Collecting bpemb>=0.3.2\n",
            "  Downloading https://files.pythonhosted.org/packages/f2/6f/9191b85109772636a8f8accb122900c34db26c091d2793218aa94954524c/bpemb-0.3.3-py3-none-any.whl\n",
            "Requirement already satisfied, skipping upgrade: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.2.3->flair) (1.3.1)\n",
            "Requirement already satisfied, skipping upgrade: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.2.3->flair) (2.4.7)\n",
            "Requirement already satisfied, skipping upgrade: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.2.3->flair) (0.10.0)\n",
            "Requirement already satisfied, skipping upgrade: packaging in /usr/local/lib/python3.7/dist-packages (from transformers>=4.0.0->flair) (20.9)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/75/ee/67241dc87f266093c533a2d4d3d69438e57d7a90abb216fa076e7d475d4a/sacremoses-0.0.45-py3-none-any.whl (895kB)\n",
            "\u001b[K     |████████████████████████████████| 901kB 31.7MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers>=4.0.0->flair) (3.10.1)\n",
            "Collecting tokenizers<0.11,>=0.10.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ae/04/5b870f26a858552025a62f1649c20d29d2672c02ff3c3fb4c688ca46467a/tokenizers-0.10.2-cp37-cp37m-manylinux2010_x86_64.whl (3.3MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3MB 42.0MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: filelock in /usr/local/lib/python3.7/dist-packages (from transformers>=4.0.0->flair) (3.0.12)\n",
            "Requirement already satisfied, skipping upgrade: requests in /usr/local/lib/python3.7/dist-packages (from transformers>=4.0.0->flair) (2.23.0)\n",
            "Requirement already satisfied, skipping upgrade: six in /usr/local/lib/python3.7/dist-packages (from langdetect->flair) (1.15.0)\n",
            "Collecting overrides<4.0.0,>=3.0.0\n",
            "  Downloading https://files.pythonhosted.org/packages/ff/b1/10f69c00947518e6676bbd43e739733048de64b8dd998e9c2d5a71f44c5d/overrides-3.1.0.tar.gz\n",
            "Requirement already satisfied, skipping upgrade: scipy>=0.17.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->flair) (1.4.1)\n",
            "Requirement already satisfied, skipping upgrade: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->flair) (1.0.1)\n",
            "Requirement already satisfied, skipping upgrade: future in /usr/local/lib/python3.7/dist-packages (from hyperopt>=0.1.1->flair) (0.16.0)\n",
            "Requirement already satisfied, skipping upgrade: networkx in /usr/local/lib/python3.7/dist-packages (from hyperopt>=0.1.1->flair) (2.5.1)\n",
            "Requirement already satisfied, skipping upgrade: pymongo in /usr/local/lib/python3.7/dist-packages (from hyperopt>=0.1.1->flair) (3.11.3)\n",
            "Requirement already satisfied, skipping upgrade: wrapt<2,>=1.10 in /usr/local/lib/python3.7/dist-packages (from deprecated>=1.2.4->flair) (1.12.1)\n",
            "Requirement already satisfied, skipping upgrade: wcwidth in /usr/local/lib/python3.7/dist-packages (from ftfy->flair) (0.2.5)\n",
            "Requirement already satisfied, skipping upgrade: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch<=1.7.1,>=1.5.0->flair) (3.7.4.3)\n",
            "Requirement already satisfied, skipping upgrade: smart-open>=1.2.1 in /usr/local/lib/python3.7/dist-packages (from gensim<=3.8.3,>=3.4.0->flair) (5.0.0)\n",
            "Requirement already satisfied, skipping upgrade: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers>=4.0.0->flair) (7.1.2)\n",
            "Requirement already satisfied, skipping upgrade: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers>=4.0.0->flair) (3.4.1)\n",
            "Requirement already satisfied, skipping upgrade: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers>=4.0.0->flair) (3.0.4)\n",
            "Requirement already satisfied, skipping upgrade: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers>=4.0.0->flair) (2.10)\n",
            "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers>=4.0.0->flair) (2020.12.5)\n",
            "Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers>=4.0.0->flair) (1.24.3)\n",
            "Requirement already satisfied, skipping upgrade: decorator<5,>=4.3 in /usr/local/lib/python3.7/dist-packages (from networkx->hyperopt>=0.1.1->flair) (4.4.2)\n",
            "Building wheels for collected packages: gdown\n",
            "  Building wheel for gdown (PEP 517) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gdown: filename=gdown-3.12.2-cp37-none-any.whl size=9693 sha256=d16653df97624b244cc5c4b9bef8b7a35e317b8e9e6f48331bbcd4bdc2f1952f\n",
            "  Stored in directory: /root/.cache/pip/wheels/81/d0/d7/d9983facc6f2775411803e0e2d30ebf98efbf2fc6e57701e09\n",
            "Successfully built gdown\n",
            "Building wheels for collected packages: langdetect, segtok, sqlitedict, mpld3, ftfy, overrides\n",
            "  Building wheel for langdetect (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for langdetect: filename=langdetect-1.0.9-cp37-none-any.whl size=993223 sha256=330183f92361e2397e8f0fbf8cd9c970a35f25e944726ff6f50a235e4a5854fa\n",
            "  Stored in directory: /root/.cache/pip/wheels/7e/18/13/038c34057808931c7ddc6c92d3aa015cf1a498df5a70268996\n",
            "  Building wheel for segtok (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for segtok: filename=segtok-1.5.10-cp37-none-any.whl size=25019 sha256=51560c179cf468a9e7cc9539f2b800417a9e6ae2a3aa5d75d7d8f0d74d722e77\n",
            "  Stored in directory: /root/.cache/pip/wheels/b4/39/f6/9ca1c5cabde964d728023b5751c3a206a5c8cc40252321fb6b\n",
            "  Building wheel for sqlitedict (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sqlitedict: filename=sqlitedict-1.7.0-cp37-none-any.whl size=14376 sha256=2de86d1d0d0f4de62eb4519c4e3f486cbd15cd894a38822dd3841e44e6d5f0d9\n",
            "  Stored in directory: /root/.cache/pip/wheels/cf/c6/4f/2c64a43f041415eb8b8740bd80e15e92f0d46c5e464d8e4b9b\n",
            "  Building wheel for mpld3 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for mpld3: filename=mpld3-0.3-cp37-none-any.whl size=116679 sha256=6df428f20e4ca037a2b559e2f35759cbf87895baa9259c02e556059e739234fe\n",
            "  Stored in directory: /root/.cache/pip/wheels/c0/47/fb/8a64f89aecfe0059830479308ad42d62e898a3e3cefdf6ba28\n",
            "  Building wheel for ftfy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ftfy: filename=ftfy-6.0.1-cp37-none-any.whl size=41573 sha256=e8bf057fe861d37a3925bde1070d69d6cc8c25093fb1532d473f85f0190d8acc\n",
            "  Stored in directory: /root/.cache/pip/wheels/ae/73/c7/9056e14b04919e5c262fe80b54133b1a88d73683d05d7ac65c\n",
            "  Building wheel for overrides (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for overrides: filename=overrides-3.1.0-cp37-none-any.whl size=10174 sha256=1c8db966dc2e10760a363b81c8039303e8d4c07ffc5bacec8ef6153794e5bcc1\n",
            "  Stored in directory: /root/.cache/pip/wheels/5c/24/13/6ef8600e6f147c95e595f1289a86a3cc82ed65df57582c65a9\n",
            "Successfully built langdetect segtok sqlitedict mpld3 ftfy overrides\n",
            "\u001b[31mERROR: torchvision 0.9.1+cu101 has requirement torch==1.8.1, but you'll have torch 1.7.1 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: torchtext 0.9.1 has requirement torch==1.8.1, but you'll have torch 1.7.1 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: konoha 4.6.4 has requirement requests<3.0.0,>=2.25.1, but you'll have requests 2.23.0 which is incompatible.\u001b[0m\n",
            "Installing collected packages: sacremoses, tokenizers, transformers, langdetect, overrides, konoha, segtok, sqlitedict, deprecated, mpld3, ftfy, torch, gdown, janome, sentencepiece, huggingface-hub, bpemb, flair\n",
            "  Found existing installation: torch 1.8.1+cu101\n",
            "    Uninstalling torch-1.8.1+cu101:\n",
            "      Successfully uninstalled torch-1.8.1+cu101\n",
            "  Found existing installation: gdown 3.6.4\n",
            "    Uninstalling gdown-3.6.4:\n",
            "      Successfully uninstalled gdown-3.6.4\n",
            "Successfully installed bpemb-0.3.3 deprecated-1.2.12 flair-0.8.0.post1 ftfy-6.0.1 gdown-3.12.2 huggingface-hub-0.0.8 janome-0.4.1 konoha-4.6.4 langdetect-1.0.9 mpld3-0.3 overrides-3.1.0 sacremoses-0.0.45 segtok-1.5.10 sentencepiece-0.1.95 sqlitedict-1.7.0 tokenizers-0.10.2 torch-1.7.1 transformers-4.5.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xg8i2W3bO-kK"
      },
      "source": [
        "from flair.data import Corpus\n",
        "from flair.datasets import ColumnCorpus, NCBI_DISEASE\n",
        "from flair.embeddings import WordEmbeddings, StackedEmbeddings, FlairEmbeddings#, TokenEmbeddings\n",
        "from typing import List"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fOPOT2KDPDrZ",
        "outputId": "dfe74e28-faca-40ff-8b34-7ea84be955c1"
      },
      "source": [
        "# define columns\n",
        "columns = {0: 'text', 1: 'ner'}\n",
        "\n",
        "# this is the folder in which train, test and dev files reside\n",
        "data_folder = '/content/drive/MyDrive/medNer'\n",
        "\n",
        "# init a corpus using column format, data folder and the names of the train, dev and test files\n",
        "corpus: Corpus = ColumnCorpus(data_folder, columns,\n",
        "                              train_file='medMentions-train.tsv',\n",
        "                              test_file='medMentions-test.tsv',\n",
        "                              dev_file='medMentions-dev.tsv')\n",
        "\n",
        "# TODO obtain and print corpus statistics (output below obtained with the BASQUE NER corpus)\n",
        "print(corpus.obtain_statistics())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-05-10 18:41:42,712 Reading data from /content/drive/MyDrive/medNer\n",
            "2021-05-10 18:41:42,719 Train: /content/drive/MyDrive/medNer/medMentions-train.tsv\n",
            "2021-05-10 18:41:42,721 Dev: /content/drive/MyDrive/medNer/medMentions-dev.tsv\n",
            "2021-05-10 18:41:42,726 Test: /content/drive/MyDrive/medNer/medMentions-test.tsv\n",
            "{\n",
            "    \"TRAIN\": {\n",
            "        \"dataset\": \"TRAIN\",\n",
            "        \"total_number_of_documents\": 25094,\n",
            "        \"number_of_documents_per_class\": {},\n",
            "        \"number_of_tokens_per_tag\": {},\n",
            "        \"number_of_tokens\": {\n",
            "            \"total\": 654178,\n",
            "            \"min\": 2,\n",
            "            \"max\": 173,\n",
            "            \"avg\": 26.069100183310752\n",
            "        }\n",
            "    },\n",
            "    \"TEST\": {\n",
            "        \"dataset\": \"TEST\",\n",
            "        \"total_number_of_documents\": 8312,\n",
            "        \"number_of_documents_per_class\": {},\n",
            "        \"number_of_tokens_per_tag\": {},\n",
            "        \"number_of_tokens\": {\n",
            "            \"total\": 219149,\n",
            "            \"min\": 2,\n",
            "            \"max\": 142,\n",
            "            \"avg\": 26.365375360923966\n",
            "        }\n",
            "    },\n",
            "    \"DEV\": {\n",
            "        \"dataset\": \"DEV\",\n",
            "        \"total_number_of_documents\": 8284,\n",
            "        \"number_of_documents_per_class\": {},\n",
            "        \"number_of_tokens_per_tag\": {},\n",
            "        \"number_of_tokens\": {\n",
            "            \"total\": 220293,\n",
            "            \"min\": 2,\n",
            "            \"max\": 158,\n",
            "            \"avg\": 26.592588121680347\n",
            "        }\n",
            "    }\n",
            "}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pPOy9UqjPltR",
        "outputId": "b95cc23a-1b38-43a9-d039-b8fdb199953d"
      },
      "source": [
        "# 2. what tag do we want to predict?\n",
        "tag_type = 'ner'\n",
        "\n",
        "# 3. make the tag dictionary from the corpus\n",
        "tag_dictionary = corpus.make_tag_dictionary(tag_type=tag_type)\n",
        "print(tag_dictionary.idx2item)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[b'<unk>', b'O', b'B-MED', b'I-MED', b'<START>', b'<STOP>']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Lp1NDgaVRvV"
      },
      "source": [
        "You can choose the embeddings. The ideal is the following combination:FlairEmbeddings('pubmed-forward'), FlairEmbeddings('pubmed-backward'), WordEmbeddings(\"pubmed\"). But due to memory issues just WordEmbeddings(\"pubmed\") is the best choice."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gHkfSkqRP9Zh",
        "outputId": "ec97038d-e12b-46f8-b398-bc2b31d4117e"
      },
      "source": [
        "embeddings : StackedEmbeddings = StackedEmbeddings([\n",
        "                                        #WordEmbeddings('glove'),\n",
        "                                        #FlairEmbeddings('news-forward'),\n",
        "                                        #FlairEmbeddings('news-backward')\n",
        "                                        #FlairEmbeddings('pubmed-forward')\n",
        "                                        #FlairEmbeddings('pubmed-backward')\n",
        "                                        WordEmbeddings(\"pubmed\"),\n",
        "\n",
        "                                        # flair embeddings trained on PubMed and PMC\n",
        "                                        #FlairEmbeddings(\"pubmed-forward\"),\n",
        "                                        #FlairEmbeddings(\"pubmed-backward\"),\n",
        "                                       ])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-05-10 18:42:07,040 https://flair.informatik.hu-berlin.de/resources/embeddings/token/pubmed_pmc_wiki_sg_1M.gensim.vectors.npy not found in cache, downloading to /tmp/tmpdjbqtepl\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 800000128/800000128 [00:20<00:00, 39744883.40B/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-05-10 18:42:27,277 copying /tmp/tmpdjbqtepl to cache at /root/.flair/embeddings/pubmed_pmc_wiki_sg_1M.gensim.vectors.npy\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-05-10 18:42:30,273 removing temp file /tmp/tmpdjbqtepl\n",
            "2021-05-10 18:42:30,529 https://flair.informatik.hu-berlin.de/resources/embeddings/token/pubmed_pmc_wiki_sg_1M.gensim not found in cache, downloading to /tmp/tmpf_trrzmm\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 53979687/53979687 [00:01<00:00, 35733992.44B/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-05-10 18:42:32,129 copying /tmp/tmpf_trrzmm to cache at /root/.flair/embeddings/pubmed_pmc_wiki_sg_1M.gensim\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-05-10 18:42:32,250 removing temp file /tmp/tmpf_trrzmm\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IxOcl_JiQ5e_",
        "outputId": "7dbbf98c-1cfb-415f-f221-a1b9503f6d98"
      },
      "source": [
        "from flair.models import SequenceTagger\n",
        "\n",
        "tagger : SequenceTagger = SequenceTagger(hidden_size=256,\n",
        "                                       embeddings=embeddings,\n",
        "                                       tag_dictionary=tag_dictionary,\n",
        "                                       tag_type=tag_type,\n",
        "                                       use_crf=True)\n",
        "print(tagger)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "SequenceTagger(\n",
            "  (embeddings): StackedEmbeddings(\n",
            "    (list_embedding_0): WordEmbeddings('pubmed')\n",
            "  )\n",
            "  (word_dropout): WordDropout(p=0.05)\n",
            "  (locked_dropout): LockedDropout(p=0.5)\n",
            "  (embedding2nn): Linear(in_features=200, out_features=200, bias=True)\n",
            "  (rnn): LSTM(200, 256, batch_first=True, bidirectional=True)\n",
            "  (linear): Linear(in_features=512, out_features=6, bias=True)\n",
            "  (beta): 1.0\n",
            "  (weights): None\n",
            "  (weight_tensor) None\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s7ckA2WKRLhX",
        "outputId": "a849179c-4a5a-4823-ae12-e2bc61b040e7"
      },
      "source": [
        "from flair.trainers import ModelTrainer\n",
        "trainer : ModelTrainer = ModelTrainer(tagger, corpus)\n",
        "trainer.train('/content/drive/MyDrive/medNer',\n",
        "              learning_rate=0.1,\n",
        "              mini_batch_size=32,\n",
        "              max_epochs=30)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-05-10 18:42:37,373 ----------------------------------------------------------------------------------------------------\n",
            "2021-05-10 18:42:37,378 Model: \"SequenceTagger(\n",
            "  (embeddings): StackedEmbeddings(\n",
            "    (list_embedding_0): WordEmbeddings('pubmed')\n",
            "  )\n",
            "  (word_dropout): WordDropout(p=0.05)\n",
            "  (locked_dropout): LockedDropout(p=0.5)\n",
            "  (embedding2nn): Linear(in_features=200, out_features=200, bias=True)\n",
            "  (rnn): LSTM(200, 256, batch_first=True, bidirectional=True)\n",
            "  (linear): Linear(in_features=512, out_features=6, bias=True)\n",
            "  (beta): 1.0\n",
            "  (weights): None\n",
            "  (weight_tensor) None\n",
            ")\"\n",
            "2021-05-10 18:42:37,383 ----------------------------------------------------------------------------------------------------\n",
            "2021-05-10 18:42:37,385 Corpus: \"Corpus: 25094 train + 8284 dev + 8312 test sentences\"\n",
            "2021-05-10 18:42:37,387 ----------------------------------------------------------------------------------------------------\n",
            "2021-05-10 18:42:37,389 Parameters:\n",
            "2021-05-10 18:42:37,392  - learning_rate: \"0.1\"\n",
            "2021-05-10 18:42:37,427  - mini_batch_size: \"32\"\n",
            "2021-05-10 18:42:37,429  - patience: \"3\"\n",
            "2021-05-10 18:42:37,432  - anneal_factor: \"0.5\"\n",
            "2021-05-10 18:42:37,435  - max_epochs: \"30\"\n",
            "2021-05-10 18:42:37,438  - shuffle: \"True\"\n",
            "2021-05-10 18:42:37,442  - train_with_dev: \"False\"\n",
            "2021-05-10 18:42:37,443  - batch_growth_annealing: \"False\"\n",
            "2021-05-10 18:42:37,446 ----------------------------------------------------------------------------------------------------\n",
            "2021-05-10 18:42:37,448 Model training base path: \"/content/drive/MyDrive/medNer\"\n",
            "2021-05-10 18:42:37,451 ----------------------------------------------------------------------------------------------------\n",
            "2021-05-10 18:42:37,453 Device: cuda:0\n",
            "2021-05-10 18:42:37,456 ----------------------------------------------------------------------------------------------------\n",
            "2021-05-10 18:42:37,457 Embeddings storage mode: cpu\n",
            "2021-05-10 18:42:37,975 ----------------------------------------------------------------------------------------------------\n",
            "2021-05-10 18:42:58,922 epoch 1 - iter 78/785 - loss 18.15497651 - samples/sec: 119.20 - lr: 0.100000\n",
            "2021-05-10 18:43:18,823 epoch 1 - iter 156/785 - loss 15.99711168 - samples/sec: 125.47 - lr: 0.100000\n",
            "2021-05-10 18:43:39,179 epoch 1 - iter 234/785 - loss 15.25780412 - samples/sec: 122.66 - lr: 0.100000\n",
            "2021-05-10 18:44:02,036 epoch 1 - iter 312/785 - loss 14.72851359 - samples/sec: 109.24 - lr: 0.100000\n",
            "2021-05-10 18:44:22,671 epoch 1 - iter 390/785 - loss 14.37384579 - samples/sec: 121.00 - lr: 0.100000\n",
            "2021-05-10 18:44:43,641 epoch 1 - iter 468/785 - loss 14.10421794 - samples/sec: 119.06 - lr: 0.100000\n",
            "2021-05-10 18:45:04,565 epoch 1 - iter 546/785 - loss 13.86314149 - samples/sec: 119.34 - lr: 0.100000\n",
            "2021-05-10 18:45:24,582 epoch 1 - iter 624/785 - loss 13.69151276 - samples/sec: 124.74 - lr: 0.100000\n",
            "2021-05-10 18:45:45,696 epoch 1 - iter 702/785 - loss 13.60134592 - samples/sec: 118.25 - lr: 0.100000\n",
            "2021-05-10 18:46:06,738 epoch 1 - iter 780/785 - loss 13.49982730 - samples/sec: 118.66 - lr: 0.100000\n",
            "2021-05-10 18:46:07,909 ----------------------------------------------------------------------------------------------------\n",
            "2021-05-10 18:46:07,911 EPOCH 1 done: loss 13.4930 - lr 0.1000000\n",
            "2021-05-10 18:46:55,453 DEV : loss 11.548288345336914 - score 0.5486\n",
            "2021-05-10 18:46:55,966 BAD EPOCHS (no improvement): 0\n",
            "saving best model\n",
            "2021-05-10 18:47:20,039 ----------------------------------------------------------------------------------------------------\n",
            "2021-05-10 18:47:39,471 epoch 2 - iter 78/785 - loss 12.27867735 - samples/sec: 128.55 - lr: 0.100000\n",
            "2021-05-10 18:47:58,928 epoch 2 - iter 156/785 - loss 12.10598047 - samples/sec: 128.35 - lr: 0.100000\n",
            "2021-05-10 18:48:16,464 epoch 2 - iter 234/785 - loss 12.05418476 - samples/sec: 142.39 - lr: 0.100000\n",
            "2021-05-10 18:48:33,688 epoch 2 - iter 312/785 - loss 11.99773198 - samples/sec: 144.98 - lr: 0.100000\n",
            "2021-05-10 18:48:50,435 epoch 2 - iter 390/785 - loss 11.94605517 - samples/sec: 149.11 - lr: 0.100000\n",
            "2021-05-10 18:49:07,415 epoch 2 - iter 468/785 - loss 11.94852904 - samples/sec: 147.07 - lr: 0.100000\n",
            "2021-05-10 18:49:24,588 epoch 2 - iter 546/785 - loss 11.94262254 - samples/sec: 145.40 - lr: 0.100000\n",
            "2021-05-10 18:49:41,386 epoch 2 - iter 624/785 - loss 11.89181616 - samples/sec: 148.65 - lr: 0.100000\n",
            "2021-05-10 18:49:59,199 epoch 2 - iter 702/785 - loss 11.86912787 - samples/sec: 140.21 - lr: 0.100000\n",
            "2021-05-10 18:50:16,932 epoch 2 - iter 780/785 - loss 11.86079094 - samples/sec: 140.82 - lr: 0.100000\n",
            "2021-05-10 18:50:17,930 ----------------------------------------------------------------------------------------------------\n",
            "2021-05-10 18:50:17,936 EPOCH 2 done: loss 11.8662 - lr 0.1000000\n",
            "2021-05-10 18:50:50,089 DEV : loss 10.159350395202637 - score 0.5571\n",
            "2021-05-10 18:50:50,619 BAD EPOCHS (no improvement): 0\n",
            "saving best model\n",
            "2021-05-10 18:51:01,828 ----------------------------------------------------------------------------------------------------\n",
            "2021-05-10 18:51:22,689 epoch 3 - iter 78/785 - loss 11.72851829 - samples/sec: 119.76 - lr: 0.100000\n",
            "2021-05-10 18:51:40,790 epoch 3 - iter 156/785 - loss 11.53746544 - samples/sec: 137.99 - lr: 0.100000\n",
            "2021-05-10 18:51:59,193 epoch 3 - iter 234/785 - loss 11.54330749 - samples/sec: 135.69 - lr: 0.100000\n",
            "2021-05-10 18:52:16,719 epoch 3 - iter 312/785 - loss 11.52026841 - samples/sec: 142.48 - lr: 0.100000\n",
            "2021-05-10 18:52:34,437 epoch 3 - iter 390/785 - loss 11.50568875 - samples/sec: 140.94 - lr: 0.100000\n",
            "2021-05-10 18:52:51,842 epoch 3 - iter 468/785 - loss 11.50406810 - samples/sec: 143.47 - lr: 0.100000\n",
            "2021-05-10 18:53:09,372 epoch 3 - iter 546/785 - loss 11.50386024 - samples/sec: 142.45 - lr: 0.100000\n",
            "2021-05-10 18:53:26,948 epoch 3 - iter 624/785 - loss 11.47738411 - samples/sec: 142.10 - lr: 0.100000\n",
            "2021-05-10 18:53:44,862 epoch 3 - iter 702/785 - loss 11.45268157 - samples/sec: 139.41 - lr: 0.100000\n",
            "2021-05-10 18:54:02,558 epoch 3 - iter 780/785 - loss 11.42440053 - samples/sec: 141.12 - lr: 0.100000\n",
            "2021-05-10 18:54:03,586 ----------------------------------------------------------------------------------------------------\n",
            "2021-05-10 18:54:03,591 EPOCH 3 done: loss 11.4207 - lr 0.1000000\n",
            "2021-05-10 18:54:36,066 DEV : loss 9.999064445495605 - score 0.595\n",
            "2021-05-10 18:54:36,581 BAD EPOCHS (no improvement): 0\n",
            "saving best model\n",
            "2021-05-10 18:54:47,713 ----------------------------------------------------------------------------------------------------\n",
            "2021-05-10 18:55:08,780 epoch 4 - iter 78/785 - loss 11.35989441 - samples/sec: 118.56 - lr: 0.100000\n",
            "2021-05-10 18:55:27,389 epoch 4 - iter 156/785 - loss 11.41625063 - samples/sec: 134.19 - lr: 0.100000\n",
            "2021-05-10 18:55:44,979 epoch 4 - iter 234/785 - loss 11.40468724 - samples/sec: 141.98 - lr: 0.100000\n",
            "2021-05-10 18:56:02,657 epoch 4 - iter 312/785 - loss 11.33364455 - samples/sec: 141.27 - lr: 0.100000\n",
            "2021-05-10 18:56:20,404 epoch 4 - iter 390/785 - loss 11.34248758 - samples/sec: 140.71 - lr: 0.100000\n",
            "2021-05-10 18:56:38,382 epoch 4 - iter 468/785 - loss 11.30117808 - samples/sec: 138.90 - lr: 0.100000\n",
            "2021-05-10 18:56:56,920 epoch 4 - iter 546/785 - loss 11.30233001 - samples/sec: 134.70 - lr: 0.100000\n",
            "2021-05-10 18:57:14,527 epoch 4 - iter 624/785 - loss 11.24029420 - samples/sec: 141.82 - lr: 0.100000\n",
            "2021-05-10 18:57:32,382 epoch 4 - iter 702/785 - loss 11.23490088 - samples/sec: 139.86 - lr: 0.100000\n",
            "2021-05-10 18:57:49,611 epoch 4 - iter 780/785 - loss 11.20425620 - samples/sec: 144.94 - lr: 0.100000\n",
            "2021-05-10 18:57:50,676 ----------------------------------------------------------------------------------------------------\n",
            "2021-05-10 18:57:50,681 EPOCH 4 done: loss 11.1990 - lr 0.1000000\n",
            "2021-05-10 18:58:23,016 DEV : loss 9.739221572875977 - score 0.5585\n",
            "2021-05-10 18:58:23,532 BAD EPOCHS (no improvement): 1\n",
            "2021-05-10 18:58:23,542 ----------------------------------------------------------------------------------------------------\n",
            "2021-05-10 18:58:41,460 epoch 5 - iter 78/785 - loss 10.99699272 - samples/sec: 139.38 - lr: 0.100000\n",
            "2021-05-10 18:58:59,188 epoch 5 - iter 156/785 - loss 10.97655737 - samples/sec: 140.86 - lr: 0.100000\n",
            "2021-05-10 18:59:17,466 epoch 5 - iter 234/785 - loss 11.06904385 - samples/sec: 136.62 - lr: 0.100000\n",
            "2021-05-10 18:59:35,308 epoch 5 - iter 312/785 - loss 11.04491475 - samples/sec: 139.96 - lr: 0.100000\n",
            "2021-05-10 18:59:52,426 epoch 5 - iter 390/785 - loss 11.03203908 - samples/sec: 145.88 - lr: 0.100000\n",
            "2021-05-10 19:00:10,369 epoch 5 - iter 468/785 - loss 11.02531303 - samples/sec: 139.17 - lr: 0.100000\n",
            "2021-05-10 19:00:27,716 epoch 5 - iter 546/785 - loss 11.03436429 - samples/sec: 143.97 - lr: 0.100000\n",
            "2021-05-10 19:00:45,500 epoch 5 - iter 624/785 - loss 11.01795765 - samples/sec: 140.42 - lr: 0.100000\n",
            "2021-05-10 19:01:03,586 epoch 5 - iter 702/785 - loss 10.99382613 - samples/sec: 138.06 - lr: 0.100000\n",
            "2021-05-10 19:01:21,093 epoch 5 - iter 780/785 - loss 10.97175889 - samples/sec: 142.64 - lr: 0.100000\n",
            "2021-05-10 19:01:22,054 ----------------------------------------------------------------------------------------------------\n",
            "2021-05-10 19:01:22,057 EPOCH 5 done: loss 10.9658 - lr 0.1000000\n",
            "2021-05-10 19:01:58,069 DEV : loss 9.728472709655762 - score 0.6109\n",
            "2021-05-10 19:01:58,571 BAD EPOCHS (no improvement): 0\n",
            "saving best model\n",
            "2021-05-10 19:02:10,125 ----------------------------------------------------------------------------------------------------\n",
            "2021-05-10 19:02:29,535 epoch 6 - iter 78/785 - loss 10.72928167 - samples/sec: 128.69 - lr: 0.100000\n",
            "2021-05-10 19:02:49,590 epoch 6 - iter 156/785 - loss 10.82516950 - samples/sec: 124.51 - lr: 0.100000\n",
            "2021-05-10 19:03:07,226 epoch 6 - iter 234/785 - loss 10.77437519 - samples/sec: 141.59 - lr: 0.100000\n",
            "2021-05-10 19:03:24,938 epoch 6 - iter 312/785 - loss 10.78331509 - samples/sec: 140.99 - lr: 0.100000\n",
            "2021-05-10 19:03:42,884 epoch 6 - iter 390/785 - loss 10.79624704 - samples/sec: 139.14 - lr: 0.100000\n",
            "2021-05-10 19:04:00,604 epoch 6 - iter 468/785 - loss 10.79735785 - samples/sec: 140.93 - lr: 0.100000\n",
            "2021-05-10 19:04:18,211 epoch 6 - iter 546/785 - loss 10.80950370 - samples/sec: 141.82 - lr: 0.100000\n",
            "2021-05-10 19:04:35,789 epoch 6 - iter 624/785 - loss 10.83214239 - samples/sec: 142.06 - lr: 0.100000\n",
            "2021-05-10 19:04:53,516 epoch 6 - iter 702/785 - loss 10.82202320 - samples/sec: 140.86 - lr: 0.100000\n",
            "2021-05-10 19:05:11,597 epoch 6 - iter 780/785 - loss 10.81358603 - samples/sec: 138.11 - lr: 0.100000\n",
            "2021-05-10 19:05:12,635 ----------------------------------------------------------------------------------------------------\n",
            "2021-05-10 19:05:12,638 EPOCH 6 done: loss 10.8128 - lr 0.1000000\n",
            "2021-05-10 19:05:44,968 DEV : loss 9.657806396484375 - score 0.5638\n",
            "2021-05-10 19:05:45,485 BAD EPOCHS (no improvement): 1\n",
            "2021-05-10 19:05:45,495 ----------------------------------------------------------------------------------------------------\n",
            "2021-05-10 19:06:02,923 epoch 7 - iter 78/785 - loss 10.47895818 - samples/sec: 143.32 - lr: 0.100000\n",
            "2021-05-10 19:06:20,674 epoch 7 - iter 156/785 - loss 10.65209825 - samples/sec: 140.68 - lr: 0.100000\n",
            "2021-05-10 19:06:38,681 epoch 7 - iter 234/785 - loss 10.58638986 - samples/sec: 138.67 - lr: 0.100000\n",
            "2021-05-10 19:06:56,700 epoch 7 - iter 312/785 - loss 10.62841085 - samples/sec: 138.60 - lr: 0.100000\n",
            "2021-05-10 19:07:14,128 epoch 7 - iter 390/785 - loss 10.63614011 - samples/sec: 143.29 - lr: 0.100000\n",
            "2021-05-10 19:07:31,275 epoch 7 - iter 468/785 - loss 10.60290127 - samples/sec: 145.63 - lr: 0.100000\n",
            "2021-05-10 19:07:48,961 epoch 7 - iter 546/785 - loss 10.61501883 - samples/sec: 141.20 - lr: 0.100000\n",
            "2021-05-10 19:08:06,912 epoch 7 - iter 624/785 - loss 10.66762821 - samples/sec: 139.10 - lr: 0.100000\n",
            "2021-05-10 19:08:24,721 epoch 7 - iter 702/785 - loss 10.67027517 - samples/sec: 140.26 - lr: 0.100000\n",
            "2021-05-10 19:08:42,773 epoch 7 - iter 780/785 - loss 10.68303906 - samples/sec: 138.33 - lr: 0.100000\n",
            "2021-05-10 19:08:43,837 ----------------------------------------------------------------------------------------------------\n",
            "2021-05-10 19:08:43,842 EPOCH 7 done: loss 10.6753 - lr 0.1000000\n",
            "2021-05-10 19:09:15,992 DEV : loss 9.380733489990234 - score 0.5966\n",
            "2021-05-10 19:09:16,512 BAD EPOCHS (no improvement): 2\n",
            "2021-05-10 19:09:16,521 ----------------------------------------------------------------------------------------------------\n",
            "2021-05-10 19:09:33,724 epoch 8 - iter 78/785 - loss 10.51164460 - samples/sec: 145.20 - lr: 0.100000\n",
            "2021-05-10 19:09:51,665 epoch 8 - iter 156/785 - loss 10.48640498 - samples/sec: 139.19 - lr: 0.100000\n",
            "2021-05-10 19:10:09,740 epoch 8 - iter 234/785 - loss 10.49936803 - samples/sec: 138.15 - lr: 0.100000\n",
            "2021-05-10 19:10:26,715 epoch 8 - iter 312/785 - loss 10.48167680 - samples/sec: 147.11 - lr: 0.100000\n",
            "2021-05-10 19:10:44,481 epoch 8 - iter 390/785 - loss 10.53226897 - samples/sec: 140.56 - lr: 0.100000\n",
            "2021-05-10 19:11:01,820 epoch 8 - iter 468/785 - loss 10.50191473 - samples/sec: 144.04 - lr: 0.100000\n",
            "2021-05-10 19:11:19,958 epoch 8 - iter 546/785 - loss 10.51836240 - samples/sec: 137.68 - lr: 0.100000\n",
            "2021-05-10 19:11:37,913 epoch 8 - iter 624/785 - loss 10.51290274 - samples/sec: 139.09 - lr: 0.100000\n",
            "2021-05-10 19:11:55,693 epoch 8 - iter 702/785 - loss 10.55467033 - samples/sec: 140.45 - lr: 0.100000\n",
            "2021-05-10 19:12:13,185 epoch 8 - iter 780/785 - loss 10.55078698 - samples/sec: 142.77 - lr: 0.100000\n",
            "2021-05-10 19:12:14,162 ----------------------------------------------------------------------------------------------------\n",
            "2021-05-10 19:12:14,164 EPOCH 8 done: loss 10.5487 - lr 0.1000000\n",
            "2021-05-10 19:12:46,556 DEV : loss 9.389243125915527 - score 0.6229\n",
            "2021-05-10 19:12:47,069 BAD EPOCHS (no improvement): 0\n",
            "saving best model\n",
            "2021-05-10 19:12:58,254 ----------------------------------------------------------------------------------------------------\n",
            "2021-05-10 19:13:18,164 epoch 9 - iter 78/785 - loss 10.47447236 - samples/sec: 125.47 - lr: 0.100000\n",
            "2021-05-10 19:13:37,478 epoch 9 - iter 156/785 - loss 10.49395087 - samples/sec: 129.29 - lr: 0.100000\n",
            "2021-05-10 19:13:55,044 epoch 9 - iter 234/785 - loss 10.56170060 - samples/sec: 142.16 - lr: 0.100000\n",
            "2021-05-10 19:14:13,438 epoch 9 - iter 312/785 - loss 10.58330075 - samples/sec: 135.76 - lr: 0.100000\n",
            "2021-05-10 19:14:30,724 epoch 9 - iter 390/785 - loss 10.51559057 - samples/sec: 144.46 - lr: 0.100000\n",
            "2021-05-10 19:14:48,492 epoch 9 - iter 468/785 - loss 10.52783112 - samples/sec: 140.54 - lr: 0.100000\n",
            "2021-05-10 19:15:05,868 epoch 9 - iter 546/785 - loss 10.49892606 - samples/sec: 143.74 - lr: 0.100000\n",
            "2021-05-10 19:15:23,248 epoch 9 - iter 624/785 - loss 10.46216122 - samples/sec: 143.68 - lr: 0.100000\n",
            "2021-05-10 19:15:40,752 epoch 9 - iter 702/785 - loss 10.44050270 - samples/sec: 142.67 - lr: 0.100000\n",
            "2021-05-10 19:15:58,635 epoch 9 - iter 780/785 - loss 10.44905541 - samples/sec: 139.64 - lr: 0.100000\n",
            "2021-05-10 19:15:59,755 ----------------------------------------------------------------------------------------------------\n",
            "2021-05-10 19:15:59,758 EPOCH 9 done: loss 10.4587 - lr 0.1000000\n",
            "2021-05-10 19:16:34,774 DEV : loss 9.286066055297852 - score 0.6189\n",
            "2021-05-10 19:16:35,288 BAD EPOCHS (no improvement): 1\n",
            "2021-05-10 19:16:35,298 ----------------------------------------------------------------------------------------------------\n",
            "2021-05-10 19:16:53,032 epoch 10 - iter 78/785 - loss 10.38696644 - samples/sec: 140.86 - lr: 0.100000\n",
            "2021-05-10 19:17:10,500 epoch 10 - iter 156/785 - loss 10.41150805 - samples/sec: 142.95 - lr: 0.100000\n",
            "2021-05-10 19:17:28,273 epoch 10 - iter 234/785 - loss 10.45127753 - samples/sec: 140.50 - lr: 0.100000\n",
            "2021-05-10 19:17:45,795 epoch 10 - iter 312/785 - loss 10.41130103 - samples/sec: 142.52 - lr: 0.100000\n",
            "2021-05-10 19:18:03,086 epoch 10 - iter 390/785 - loss 10.40879126 - samples/sec: 144.42 - lr: 0.100000\n",
            "2021-05-10 19:18:20,205 epoch 10 - iter 468/785 - loss 10.38364942 - samples/sec: 145.93 - lr: 0.100000\n",
            "2021-05-10 19:18:37,594 epoch 10 - iter 546/785 - loss 10.36923116 - samples/sec: 143.60 - lr: 0.100000\n",
            "2021-05-10 19:18:55,077 epoch 10 - iter 624/785 - loss 10.36232647 - samples/sec: 142.85 - lr: 0.100000\n",
            "2021-05-10 19:19:12,481 epoch 10 - iter 702/785 - loss 10.36389734 - samples/sec: 143.48 - lr: 0.100000\n",
            "2021-05-10 19:19:30,436 epoch 10 - iter 780/785 - loss 10.37143252 - samples/sec: 139.07 - lr: 0.100000\n",
            "2021-05-10 19:19:31,518 ----------------------------------------------------------------------------------------------------\n",
            "2021-05-10 19:19:31,521 EPOCH 10 done: loss 10.3901 - lr 0.1000000\n",
            "2021-05-10 19:20:03,442 DEV : loss 9.221763610839844 - score 0.6087\n",
            "2021-05-10 19:20:03,954 BAD EPOCHS (no improvement): 2\n",
            "2021-05-10 19:20:03,963 ----------------------------------------------------------------------------------------------------\n",
            "2021-05-10 19:20:21,734 epoch 11 - iter 78/785 - loss 10.23505574 - samples/sec: 140.54 - lr: 0.100000\n",
            "2021-05-10 19:20:38,931 epoch 11 - iter 156/785 - loss 10.25919118 - samples/sec: 145.21 - lr: 0.100000\n",
            "2021-05-10 19:20:56,425 epoch 11 - iter 234/785 - loss 10.25693524 - samples/sec: 142.74 - lr: 0.100000\n",
            "2021-05-10 19:21:13,918 epoch 11 - iter 312/785 - loss 10.25264930 - samples/sec: 142.75 - lr: 0.100000\n",
            "2021-05-10 19:21:31,508 epoch 11 - iter 390/785 - loss 10.22751844 - samples/sec: 141.97 - lr: 0.100000\n",
            "2021-05-10 19:21:49,404 epoch 11 - iter 468/785 - loss 10.25651479 - samples/sec: 139.53 - lr: 0.100000\n",
            "2021-05-10 19:22:07,280 epoch 11 - iter 546/785 - loss 10.24960043 - samples/sec: 139.68 - lr: 0.100000\n",
            "2021-05-10 19:22:24,874 epoch 11 - iter 624/785 - loss 10.26654410 - samples/sec: 141.97 - lr: 0.100000\n",
            "2021-05-10 19:22:42,159 epoch 11 - iter 702/785 - loss 10.26688551 - samples/sec: 144.47 - lr: 0.100000\n",
            "2021-05-10 19:23:00,287 epoch 11 - iter 780/785 - loss 10.28232460 - samples/sec: 137.75 - lr: 0.100000\n",
            "2021-05-10 19:23:01,453 ----------------------------------------------------------------------------------------------------\n",
            "2021-05-10 19:23:01,456 EPOCH 11 done: loss 10.2954 - lr 0.1000000\n",
            "2021-05-10 19:23:33,857 DEV : loss 9.022771835327148 - score 0.6328\n",
            "2021-05-10 19:23:34,373 BAD EPOCHS (no improvement): 0\n",
            "saving best model\n",
            "2021-05-10 19:23:45,284 ----------------------------------------------------------------------------------------------------\n",
            "2021-05-10 19:24:05,635 epoch 12 - iter 78/785 - loss 10.43352052 - samples/sec: 122.72 - lr: 0.100000\n",
            "2021-05-10 19:24:24,223 epoch 12 - iter 156/785 - loss 10.32097991 - samples/sec: 134.34 - lr: 0.100000\n",
            "2021-05-10 19:24:42,314 epoch 12 - iter 234/785 - loss 10.30594442 - samples/sec: 138.03 - lr: 0.100000\n",
            "2021-05-10 19:25:00,259 epoch 12 - iter 312/785 - loss 10.30794603 - samples/sec: 139.16 - lr: 0.100000\n",
            "2021-05-10 19:25:17,668 epoch 12 - iter 390/785 - loss 10.24032790 - samples/sec: 143.44 - lr: 0.100000\n",
            "2021-05-10 19:25:35,261 epoch 12 - iter 468/785 - loss 10.22649185 - samples/sec: 141.94 - lr: 0.100000\n",
            "2021-05-10 19:25:53,288 epoch 12 - iter 546/785 - loss 10.22763151 - samples/sec: 138.53 - lr: 0.100000\n",
            "2021-05-10 19:26:11,304 epoch 12 - iter 624/785 - loss 10.21508582 - samples/sec: 138.60 - lr: 0.100000\n",
            "2021-05-10 19:26:28,802 epoch 12 - iter 702/785 - loss 10.21968478 - samples/sec: 142.73 - lr: 0.100000\n",
            "2021-05-10 19:26:46,457 epoch 12 - iter 780/785 - loss 10.21787535 - samples/sec: 141.44 - lr: 0.100000\n",
            "2021-05-10 19:26:47,413 ----------------------------------------------------------------------------------------------------\n",
            "2021-05-10 19:26:47,416 EPOCH 12 done: loss 10.2128 - lr 0.1000000\n",
            "2021-05-10 19:27:19,553 DEV : loss 9.197613716125488 - score 0.5945\n",
            "2021-05-10 19:27:20,073 BAD EPOCHS (no improvement): 1\n",
            "2021-05-10 19:27:20,099 ----------------------------------------------------------------------------------------------------\n",
            "2021-05-10 19:27:37,463 epoch 13 - iter 78/785 - loss 9.92138761 - samples/sec: 143.87 - lr: 0.100000\n",
            "2021-05-10 19:27:55,391 epoch 13 - iter 156/785 - loss 10.00582321 - samples/sec: 139.29 - lr: 0.100000\n",
            "2021-05-10 19:28:12,537 epoch 13 - iter 234/785 - loss 10.08584177 - samples/sec: 145.73 - lr: 0.100000\n",
            "2021-05-10 19:28:30,275 epoch 13 - iter 312/785 - loss 10.15790392 - samples/sec: 140.79 - lr: 0.100000\n",
            "2021-05-10 19:28:47,956 epoch 13 - iter 390/785 - loss 10.12741616 - samples/sec: 141.24 - lr: 0.100000\n",
            "2021-05-10 19:29:06,136 epoch 13 - iter 468/785 - loss 10.20137318 - samples/sec: 137.35 - lr: 0.100000\n",
            "2021-05-10 19:29:23,501 epoch 13 - iter 546/785 - loss 10.18628872 - samples/sec: 143.82 - lr: 0.100000\n",
            "2021-05-10 19:29:41,313 epoch 13 - iter 624/785 - loss 10.19088856 - samples/sec: 140.19 - lr: 0.100000\n",
            "2021-05-10 19:29:58,734 epoch 13 - iter 702/785 - loss 10.19495859 - samples/sec: 143.34 - lr: 0.100000\n",
            "2021-05-10 19:30:16,481 epoch 13 - iter 780/785 - loss 10.18998685 - samples/sec: 140.70 - lr: 0.100000\n",
            "2021-05-10 19:30:17,453 ----------------------------------------------------------------------------------------------------\n",
            "2021-05-10 19:30:17,455 EPOCH 13 done: loss 10.1842 - lr 0.1000000\n",
            "2021-05-10 19:30:49,726 DEV : loss 9.324247360229492 - score 0.6145\n",
            "2021-05-10 19:30:50,253 BAD EPOCHS (no improvement): 2\n",
            "2021-05-10 19:30:50,261 ----------------------------------------------------------------------------------------------------\n",
            "2021-05-10 19:31:08,108 epoch 14 - iter 78/785 - loss 10.06109656 - samples/sec: 139.95 - lr: 0.100000\n",
            "2021-05-10 19:31:25,572 epoch 14 - iter 156/785 - loss 9.99933474 - samples/sec: 143.00 - lr: 0.100000\n",
            "2021-05-10 19:31:42,852 epoch 14 - iter 234/785 - loss 9.94277139 - samples/sec: 144.51 - lr: 0.100000\n",
            "2021-05-10 19:32:00,627 epoch 14 - iter 312/785 - loss 10.01151546 - samples/sec: 140.48 - lr: 0.100000\n",
            "2021-05-10 19:32:21,277 epoch 14 - iter 390/785 - loss 9.99055105 - samples/sec: 120.91 - lr: 0.100000\n",
            "2021-05-10 19:32:39,100 epoch 14 - iter 468/785 - loss 10.01035984 - samples/sec: 140.11 - lr: 0.100000\n",
            "2021-05-10 19:32:57,139 epoch 14 - iter 546/785 - loss 10.09251060 - samples/sec: 138.43 - lr: 0.100000\n",
            "2021-05-10 19:33:14,474 epoch 14 - iter 624/785 - loss 10.09521083 - samples/sec: 144.06 - lr: 0.100000\n",
            "2021-05-10 19:33:32,015 epoch 14 - iter 702/785 - loss 10.08006108 - samples/sec: 142.36 - lr: 0.100000\n",
            "2021-05-10 19:33:49,852 epoch 14 - iter 780/785 - loss 10.12237393 - samples/sec: 140.01 - lr: 0.100000\n",
            "2021-05-10 19:33:50,844 ----------------------------------------------------------------------------------------------------\n",
            "2021-05-10 19:33:50,847 EPOCH 14 done: loss 10.1239 - lr 0.1000000\n",
            "2021-05-10 19:34:23,179 DEV : loss 9.018321990966797 - score 0.6312\n",
            "2021-05-10 19:34:23,692 BAD EPOCHS (no improvement): 3\n",
            "2021-05-10 19:34:23,701 ----------------------------------------------------------------------------------------------------\n",
            "2021-05-10 19:34:41,538 epoch 15 - iter 78/785 - loss 10.26622052 - samples/sec: 140.01 - lr: 0.100000\n",
            "2021-05-10 19:34:59,401 epoch 15 - iter 156/785 - loss 10.22832702 - samples/sec: 139.85 - lr: 0.100000\n",
            "2021-05-10 19:35:17,090 epoch 15 - iter 234/785 - loss 10.15823535 - samples/sec: 141.20 - lr: 0.100000\n",
            "2021-05-10 19:35:34,079 epoch 15 - iter 312/785 - loss 10.08830225 - samples/sec: 146.99 - lr: 0.100000\n",
            "2021-05-10 19:35:51,565 epoch 15 - iter 390/785 - loss 10.09211921 - samples/sec: 142.81 - lr: 0.100000\n",
            "2021-05-10 19:36:09,464 epoch 15 - iter 468/785 - loss 10.11960999 - samples/sec: 139.51 - lr: 0.100000\n",
            "2021-05-10 19:36:26,902 epoch 15 - iter 546/785 - loss 10.11615636 - samples/sec: 143.21 - lr: 0.100000\n",
            "2021-05-10 19:36:44,899 epoch 15 - iter 624/785 - loss 10.13290556 - samples/sec: 138.74 - lr: 0.100000\n",
            "2021-05-10 19:37:02,654 epoch 15 - iter 702/785 - loss 10.13530518 - samples/sec: 140.65 - lr: 0.100000\n",
            "2021-05-10 19:37:19,783 epoch 15 - iter 780/785 - loss 10.08376665 - samples/sec: 145.79 - lr: 0.100000\n",
            "2021-05-10 19:37:20,783 ----------------------------------------------------------------------------------------------------\n",
            "2021-05-10 19:37:20,787 EPOCH 15 done: loss 10.0821 - lr 0.1000000\n",
            "2021-05-10 19:37:53,013 DEV : loss 8.882484436035156 - score 0.6251\n",
            "Epoch    15: reducing learning rate of group 0 to 5.0000e-02.\n",
            "2021-05-10 19:37:53,538 BAD EPOCHS (no improvement): 4\n",
            "2021-05-10 19:37:53,548 ----------------------------------------------------------------------------------------------------\n",
            "2021-05-10 19:38:11,268 epoch 16 - iter 78/785 - loss 9.85274403 - samples/sec: 140.97 - lr: 0.050000\n",
            "2021-05-10 19:38:28,905 epoch 16 - iter 156/785 - loss 9.68647812 - samples/sec: 141.59 - lr: 0.050000\n",
            "2021-05-10 19:38:46,356 epoch 16 - iter 234/785 - loss 9.81256636 - samples/sec: 143.12 - lr: 0.050000\n",
            "2021-05-10 19:39:04,177 epoch 16 - iter 312/785 - loss 9.81453338 - samples/sec: 140.13 - lr: 0.050000\n",
            "2021-05-10 19:39:21,598 epoch 16 - iter 390/785 - loss 9.82480044 - samples/sec: 143.37 - lr: 0.050000\n",
            "2021-05-10 19:39:39,116 epoch 16 - iter 468/785 - loss 9.81637912 - samples/sec: 142.55 - lr: 0.050000\n",
            "2021-05-10 19:39:57,011 epoch 16 - iter 546/785 - loss 9.84094083 - samples/sec: 139.55 - lr: 0.050000\n",
            "2021-05-10 19:40:14,919 epoch 16 - iter 624/785 - loss 9.82381345 - samples/sec: 139.43 - lr: 0.050000\n",
            "2021-05-10 19:40:32,522 epoch 16 - iter 702/785 - loss 9.84318995 - samples/sec: 141.86 - lr: 0.050000\n",
            "2021-05-10 19:40:50,007 epoch 16 - iter 780/785 - loss 9.84501516 - samples/sec: 142.84 - lr: 0.050000\n",
            "2021-05-10 19:40:50,985 ----------------------------------------------------------------------------------------------------\n",
            "2021-05-10 19:40:50,987 EPOCH 16 done: loss 9.8413 - lr 0.0500000\n",
            "2021-05-10 19:41:23,610 DEV : loss 8.902117729187012 - score 0.6476\n",
            "2021-05-10 19:41:24,118 BAD EPOCHS (no improvement): 0\n",
            "saving best model\n",
            "2021-05-10 19:41:35,183 ----------------------------------------------------------------------------------------------------\n",
            "2021-05-10 19:41:55,163 epoch 17 - iter 78/785 - loss 9.86837148 - samples/sec: 125.01 - lr: 0.050000\n",
            "2021-05-10 19:42:14,943 epoch 17 - iter 156/785 - loss 9.85912404 - samples/sec: 126.24 - lr: 0.050000\n",
            "2021-05-10 19:42:32,480 epoch 17 - iter 234/785 - loss 9.78872357 - samples/sec: 142.39 - lr: 0.050000\n",
            "2021-05-10 19:42:50,483 epoch 17 - iter 312/785 - loss 9.80734342 - samples/sec: 138.71 - lr: 0.050000\n",
            "2021-05-10 19:43:07,942 epoch 17 - iter 390/785 - loss 9.78025260 - samples/sec: 143.03 - lr: 0.050000\n",
            "2021-05-10 19:43:25,742 epoch 17 - iter 468/785 - loss 9.74774083 - samples/sec: 140.29 - lr: 0.050000\n",
            "2021-05-10 19:43:43,428 epoch 17 - iter 546/785 - loss 9.79223619 - samples/sec: 141.19 - lr: 0.050000\n",
            "2021-05-10 19:44:00,977 epoch 17 - iter 624/785 - loss 9.78002445 - samples/sec: 142.29 - lr: 0.050000\n",
            "2021-05-10 19:44:18,398 epoch 17 - iter 702/785 - loss 9.78838885 - samples/sec: 143.34 - lr: 0.050000\n",
            "2021-05-10 19:44:35,738 epoch 17 - iter 780/785 - loss 9.79566109 - samples/sec: 144.02 - lr: 0.050000\n",
            "2021-05-10 19:44:36,742 ----------------------------------------------------------------------------------------------------\n",
            "2021-05-10 19:44:36,745 EPOCH 17 done: loss 9.7950 - lr 0.0500000\n",
            "2021-05-10 19:45:08,853 DEV : loss 8.950234413146973 - score 0.6444\n",
            "2021-05-10 19:45:09,365 BAD EPOCHS (no improvement): 1\n",
            "2021-05-10 19:45:09,377 ----------------------------------------------------------------------------------------------------\n",
            "2021-05-10 19:45:26,870 epoch 18 - iter 78/785 - loss 9.76200554 - samples/sec: 142.80 - lr: 0.050000\n",
            "2021-05-10 19:45:43,814 epoch 18 - iter 156/785 - loss 9.60164821 - samples/sec: 147.38 - lr: 0.050000\n",
            "2021-05-10 19:46:01,670 epoch 18 - iter 234/785 - loss 9.63221013 - samples/sec: 139.85 - lr: 0.050000\n",
            "2021-05-10 19:46:20,031 epoch 18 - iter 312/785 - loss 9.70522267 - samples/sec: 136.04 - lr: 0.050000\n",
            "2021-05-10 19:46:37,517 epoch 18 - iter 390/785 - loss 9.73384383 - samples/sec: 142.82 - lr: 0.050000\n",
            "2021-05-10 19:46:54,680 epoch 18 - iter 468/785 - loss 9.73449715 - samples/sec: 145.49 - lr: 0.050000\n",
            "2021-05-10 19:47:12,112 epoch 18 - iter 546/785 - loss 9.73819938 - samples/sec: 143.26 - lr: 0.050000\n",
            "2021-05-10 19:47:29,464 epoch 18 - iter 624/785 - loss 9.74815395 - samples/sec: 143.92 - lr: 0.050000\n",
            "2021-05-10 19:47:46,326 epoch 18 - iter 702/785 - loss 9.73951919 - samples/sec: 148.10 - lr: 0.050000\n",
            "2021-05-10 19:48:04,232 epoch 18 - iter 780/785 - loss 9.75281099 - samples/sec: 139.49 - lr: 0.050000\n",
            "2021-05-10 19:48:05,193 ----------------------------------------------------------------------------------------------------\n",
            "2021-05-10 19:48:05,197 EPOCH 18 done: loss 9.7446 - lr 0.0500000\n",
            "2021-05-10 19:48:40,233 DEV : loss 8.889472007751465 - score 0.6022\n",
            "2021-05-10 19:48:40,768 BAD EPOCHS (no improvement): 2\n",
            "2021-05-10 19:48:40,778 ----------------------------------------------------------------------------------------------------\n",
            "2021-05-10 19:48:58,511 epoch 19 - iter 78/785 - loss 9.93984209 - samples/sec: 140.87 - lr: 0.050000\n",
            "2021-05-10 19:49:15,939 epoch 19 - iter 156/785 - loss 9.83502639 - samples/sec: 143.28 - lr: 0.050000\n",
            "2021-05-10 19:49:33,788 epoch 19 - iter 234/785 - loss 9.70809291 - samples/sec: 139.92 - lr: 0.050000\n",
            "2021-05-10 19:49:51,435 epoch 19 - iter 312/785 - loss 9.70463627 - samples/sec: 141.51 - lr: 0.050000\n",
            "2021-05-10 19:50:08,621 epoch 19 - iter 390/785 - loss 9.70819704 - samples/sec: 145.30 - lr: 0.050000\n",
            "2021-05-10 19:50:26,368 epoch 19 - iter 468/785 - loss 9.73669241 - samples/sec: 140.78 - lr: 0.050000\n",
            "2021-05-10 19:50:43,388 epoch 19 - iter 546/785 - loss 9.72733451 - samples/sec: 146.72 - lr: 0.050000\n",
            "2021-05-10 19:51:00,847 epoch 19 - iter 624/785 - loss 9.73157848 - samples/sec: 143.03 - lr: 0.050000\n",
            "2021-05-10 19:51:17,958 epoch 19 - iter 702/785 - loss 9.70371034 - samples/sec: 145.94 - lr: 0.050000\n",
            "2021-05-10 19:51:35,902 epoch 19 - iter 780/785 - loss 9.72090419 - samples/sec: 139.17 - lr: 0.050000\n",
            "2021-05-10 19:51:37,076 ----------------------------------------------------------------------------------------------------\n",
            "2021-05-10 19:51:37,079 EPOCH 19 done: loss 9.7251 - lr 0.0500000\n",
            "2021-05-10 19:52:09,304 DEV : loss 8.864509582519531 - score 0.6557\n",
            "2021-05-10 19:52:09,834 BAD EPOCHS (no improvement): 0\n",
            "saving best model\n",
            "2021-05-10 19:52:21,123 ----------------------------------------------------------------------------------------------------\n",
            "2021-05-10 19:52:41,147 epoch 20 - iter 78/785 - loss 9.81815152 - samples/sec: 124.74 - lr: 0.050000\n",
            "2021-05-10 19:52:59,985 epoch 20 - iter 156/785 - loss 9.74286622 - samples/sec: 132.56 - lr: 0.050000\n",
            "2021-05-10 19:53:17,319 epoch 20 - iter 234/785 - loss 9.72508540 - samples/sec: 144.06 - lr: 0.050000\n",
            "2021-05-10 19:53:34,716 epoch 20 - iter 312/785 - loss 9.71830313 - samples/sec: 143.53 - lr: 0.050000\n",
            "2021-05-10 19:53:52,267 epoch 20 - iter 390/785 - loss 9.72815235 - samples/sec: 142.29 - lr: 0.050000\n",
            "2021-05-10 19:54:10,032 epoch 20 - iter 468/785 - loss 9.69362130 - samples/sec: 140.58 - lr: 0.050000\n",
            "2021-05-10 19:54:27,315 epoch 20 - iter 546/785 - loss 9.67604503 - samples/sec: 144.48 - lr: 0.050000\n",
            "2021-05-10 19:54:44,749 epoch 20 - iter 624/785 - loss 9.68648312 - samples/sec: 143.23 - lr: 0.050000\n",
            "2021-05-10 19:55:02,413 epoch 20 - iter 702/785 - loss 9.68420481 - samples/sec: 141.37 - lr: 0.050000\n",
            "2021-05-10 19:55:19,884 epoch 20 - iter 780/785 - loss 9.69651690 - samples/sec: 142.94 - lr: 0.050000\n",
            "2021-05-10 19:55:21,040 ----------------------------------------------------------------------------------------------------\n",
            "2021-05-10 19:55:21,044 EPOCH 20 done: loss 9.7035 - lr 0.0500000\n",
            "2021-05-10 19:55:52,793 DEV : loss 8.786365509033203 - score 0.6114\n",
            "2021-05-10 19:55:53,306 BAD EPOCHS (no improvement): 1\n",
            "2021-05-10 19:55:53,313 ----------------------------------------------------------------------------------------------------\n",
            "2021-05-10 19:56:10,872 epoch 21 - iter 78/785 - loss 9.71822396 - samples/sec: 142.24 - lr: 0.050000\n",
            "2021-05-10 19:56:28,502 epoch 21 - iter 156/785 - loss 9.61329769 - samples/sec: 141.66 - lr: 0.050000\n",
            "2021-05-10 19:56:45,998 epoch 21 - iter 234/785 - loss 9.59825350 - samples/sec: 142.72 - lr: 0.050000\n",
            "2021-05-10 19:57:03,487 epoch 21 - iter 312/785 - loss 9.68012970 - samples/sec: 142.82 - lr: 0.050000\n",
            "2021-05-10 19:57:20,402 epoch 21 - iter 390/785 - loss 9.65607923 - samples/sec: 147.63 - lr: 0.050000\n",
            "2021-05-10 19:57:37,962 epoch 21 - iter 468/785 - loss 9.68966207 - samples/sec: 142.20 - lr: 0.050000\n",
            "2021-05-10 19:57:55,595 epoch 21 - iter 546/785 - loss 9.70588925 - samples/sec: 141.62 - lr: 0.050000\n",
            "2021-05-10 19:58:13,128 epoch 21 - iter 624/785 - loss 9.70659987 - samples/sec: 142.46 - lr: 0.050000\n",
            "2021-05-10 19:58:30,576 epoch 21 - iter 702/785 - loss 9.68757188 - samples/sec: 143.13 - lr: 0.050000\n",
            "2021-05-10 19:58:48,344 epoch 21 - iter 780/785 - loss 9.70064317 - samples/sec: 140.53 - lr: 0.050000\n",
            "2021-05-10 19:58:49,281 ----------------------------------------------------------------------------------------------------\n",
            "2021-05-10 19:58:49,284 EPOCH 21 done: loss 9.6992 - lr 0.0500000\n",
            "2021-05-10 19:59:21,242 DEV : loss 8.770769119262695 - score 0.6372\n",
            "2021-05-10 19:59:21,759 BAD EPOCHS (no improvement): 2\n",
            "2021-05-10 19:59:21,769 ----------------------------------------------------------------------------------------------------\n",
            "2021-05-10 19:59:39,313 epoch 22 - iter 78/785 - loss 9.52638497 - samples/sec: 142.36 - lr: 0.050000\n",
            "2021-05-10 19:59:56,818 epoch 22 - iter 156/785 - loss 9.49885239 - samples/sec: 142.65 - lr: 0.050000\n",
            "2021-05-10 20:00:14,189 epoch 22 - iter 234/785 - loss 9.58963106 - samples/sec: 143.75 - lr: 0.050000\n",
            "2021-05-10 20:00:31,750 epoch 22 - iter 312/785 - loss 9.68241665 - samples/sec: 142.20 - lr: 0.050000\n",
            "2021-05-10 20:00:49,517 epoch 22 - iter 390/785 - loss 9.68471770 - samples/sec: 140.55 - lr: 0.050000\n",
            "2021-05-10 20:01:06,656 epoch 22 - iter 468/785 - loss 9.69359073 - samples/sec: 145.70 - lr: 0.050000\n",
            "2021-05-10 20:01:24,083 epoch 22 - iter 546/785 - loss 9.66886943 - samples/sec: 143.28 - lr: 0.050000\n",
            "2021-05-10 20:01:41,577 epoch 22 - iter 624/785 - loss 9.68467652 - samples/sec: 142.74 - lr: 0.050000\n",
            "2021-05-10 20:01:58,974 epoch 22 - iter 702/785 - loss 9.67405632 - samples/sec: 143.54 - lr: 0.050000\n",
            "2021-05-10 20:02:16,535 epoch 22 - iter 780/785 - loss 9.67749400 - samples/sec: 142.23 - lr: 0.050000\n",
            "2021-05-10 20:02:17,608 ----------------------------------------------------------------------------------------------------\n",
            "2021-05-10 20:02:17,610 EPOCH 22 done: loss 9.6782 - lr 0.0500000\n",
            "2021-05-10 20:02:52,695 DEV : loss 8.796380043029785 - score 0.6464\n",
            "2021-05-10 20:02:53,223 BAD EPOCHS (no improvement): 3\n",
            "2021-05-10 20:02:53,234 ----------------------------------------------------------------------------------------------------\n",
            "2021-05-10 20:03:10,813 epoch 23 - iter 78/785 - loss 9.64686011 - samples/sec: 142.09 - lr: 0.050000\n",
            "2021-05-10 20:03:27,845 epoch 23 - iter 156/785 - loss 9.50922457 - samples/sec: 146.62 - lr: 0.050000\n",
            "2021-05-10 20:03:44,823 epoch 23 - iter 234/785 - loss 9.51830336 - samples/sec: 147.08 - lr: 0.050000\n",
            "2021-05-10 20:04:02,532 epoch 23 - iter 312/785 - loss 9.60476415 - samples/sec: 141.02 - lr: 0.050000\n",
            "2021-05-10 20:04:19,990 epoch 23 - iter 390/785 - loss 9.62884709 - samples/sec: 143.04 - lr: 0.050000\n",
            "2021-05-10 20:04:37,199 epoch 23 - iter 468/785 - loss 9.58009329 - samples/sec: 145.10 - lr: 0.050000\n",
            "2021-05-10 20:04:54,721 epoch 23 - iter 546/785 - loss 9.60262755 - samples/sec: 142.53 - lr: 0.050000\n",
            "2021-05-10 20:05:12,208 epoch 23 - iter 624/785 - loss 9.62687314 - samples/sec: 142.80 - lr: 0.050000\n",
            "2021-05-10 20:05:30,216 epoch 23 - iter 702/785 - loss 9.63006189 - samples/sec: 138.71 - lr: 0.050000\n",
            "2021-05-10 20:05:47,672 epoch 23 - iter 780/785 - loss 9.64806725 - samples/sec: 143.06 - lr: 0.050000\n",
            "2021-05-10 20:05:48,671 ----------------------------------------------------------------------------------------------------\n",
            "2021-05-10 20:05:48,672 EPOCH 23 done: loss 9.6501 - lr 0.0500000\n",
            "2021-05-10 20:06:20,447 DEV : loss 8.788394927978516 - score 0.6349\n",
            "Epoch    23: reducing learning rate of group 0 to 2.5000e-02.\n",
            "2021-05-10 20:06:20,973 BAD EPOCHS (no improvement): 4\n",
            "2021-05-10 20:06:20,982 ----------------------------------------------------------------------------------------------------\n",
            "2021-05-10 20:06:38,575 epoch 24 - iter 78/785 - loss 9.87667255 - samples/sec: 141.97 - lr: 0.025000\n",
            "2021-05-10 20:06:56,230 epoch 24 - iter 156/785 - loss 9.69836849 - samples/sec: 141.44 - lr: 0.025000\n",
            "2021-05-10 20:07:13,552 epoch 24 - iter 234/785 - loss 9.66051848 - samples/sec: 144.15 - lr: 0.025000\n",
            "2021-05-10 20:07:30,999 epoch 24 - iter 312/785 - loss 9.60740299 - samples/sec: 143.12 - lr: 0.025000\n",
            "2021-05-10 20:07:48,629 epoch 24 - iter 390/785 - loss 9.61872747 - samples/sec: 141.64 - lr: 0.025000\n",
            "2021-05-10 20:08:06,339 epoch 24 - iter 468/785 - loss 9.63873707 - samples/sec: 141.04 - lr: 0.025000\n",
            "2021-05-10 20:08:23,959 epoch 24 - iter 546/785 - loss 9.62846261 - samples/sec: 141.72 - lr: 0.025000\n",
            "2021-05-10 20:08:41,207 epoch 24 - iter 624/785 - loss 9.59535032 - samples/sec: 144.78 - lr: 0.025000\n",
            "2021-05-10 20:08:58,552 epoch 24 - iter 702/785 - loss 9.58467783 - samples/sec: 143.96 - lr: 0.025000\n",
            "2021-05-10 20:09:15,782 epoch 24 - iter 780/785 - loss 9.56487988 - samples/sec: 144.94 - lr: 0.025000\n",
            "2021-05-10 20:09:16,849 ----------------------------------------------------------------------------------------------------\n",
            "2021-05-10 20:09:16,851 EPOCH 24 done: loss 9.5672 - lr 0.0250000\n",
            "2021-05-10 20:09:49,025 DEV : loss 8.691374778747559 - score 0.6492\n",
            "2021-05-10 20:09:49,534 BAD EPOCHS (no improvement): 1\n",
            "2021-05-10 20:09:49,543 ----------------------------------------------------------------------------------------------------\n",
            "2021-05-10 20:10:07,438 epoch 25 - iter 78/785 - loss 9.63484298 - samples/sec: 139.59 - lr: 0.025000\n",
            "2021-05-10 20:10:25,659 epoch 25 - iter 156/785 - loss 9.75225693 - samples/sec: 137.05 - lr: 0.025000\n",
            "2021-05-10 20:10:42,886 epoch 25 - iter 234/785 - loss 9.64663037 - samples/sec: 144.96 - lr: 0.025000\n",
            "2021-05-10 20:10:59,991 epoch 25 - iter 312/785 - loss 9.58424404 - samples/sec: 145.99 - lr: 0.025000\n",
            "2021-05-10 20:11:17,503 epoch 25 - iter 390/785 - loss 9.53436055 - samples/sec: 142.60 - lr: 0.025000\n",
            "2021-05-10 20:11:34,866 epoch 25 - iter 468/785 - loss 9.53413864 - samples/sec: 143.83 - lr: 0.025000\n",
            "2021-05-10 20:11:52,216 epoch 25 - iter 546/785 - loss 9.51924622 - samples/sec: 143.94 - lr: 0.025000\n",
            "2021-05-10 20:12:10,346 epoch 25 - iter 624/785 - loss 9.54938642 - samples/sec: 137.73 - lr: 0.025000\n",
            "2021-05-10 20:12:27,655 epoch 25 - iter 702/785 - loss 9.53726342 - samples/sec: 144.28 - lr: 0.025000\n",
            "2021-05-10 20:12:44,867 epoch 25 - iter 780/785 - loss 9.52399941 - samples/sec: 145.08 - lr: 0.025000\n",
            "2021-05-10 20:12:45,800 ----------------------------------------------------------------------------------------------------\n",
            "2021-05-10 20:12:45,803 EPOCH 25 done: loss 9.5172 - lr 0.0250000\n",
            "2021-05-10 20:13:17,889 DEV : loss 8.662339210510254 - score 0.6425\n",
            "2021-05-10 20:13:18,409 BAD EPOCHS (no improvement): 2\n",
            "2021-05-10 20:13:18,416 ----------------------------------------------------------------------------------------------------\n",
            "2021-05-10 20:13:35,884 epoch 26 - iter 78/785 - loss 9.49279686 - samples/sec: 142.99 - lr: 0.025000\n",
            "2021-05-10 20:13:52,589 epoch 26 - iter 156/785 - loss 9.43043931 - samples/sec: 149.49 - lr: 0.025000\n",
            "2021-05-10 20:14:09,569 epoch 26 - iter 234/785 - loss 9.42692415 - samples/sec: 147.07 - lr: 0.025000\n",
            "2021-05-10 20:14:26,628 epoch 26 - iter 312/785 - loss 9.47697630 - samples/sec: 146.37 - lr: 0.025000\n",
            "2021-05-10 20:14:43,650 epoch 26 - iter 390/785 - loss 9.49999667 - samples/sec: 146.72 - lr: 0.025000\n",
            "2021-05-10 20:15:00,737 epoch 26 - iter 468/785 - loss 9.49734734 - samples/sec: 146.17 - lr: 0.025000\n",
            "2021-05-10 20:15:18,907 epoch 26 - iter 546/785 - loss 9.49857901 - samples/sec: 137.44 - lr: 0.025000\n",
            "2021-05-10 20:15:36,275 epoch 26 - iter 624/785 - loss 9.50072054 - samples/sec: 143.78 - lr: 0.025000\n",
            "2021-05-10 20:15:53,736 epoch 26 - iter 702/785 - loss 9.50610148 - samples/sec: 143.06 - lr: 0.025000\n",
            "2021-05-10 20:16:11,207 epoch 26 - iter 780/785 - loss 9.50283325 - samples/sec: 142.96 - lr: 0.025000\n",
            "2021-05-10 20:16:12,157 ----------------------------------------------------------------------------------------------------\n",
            "2021-05-10 20:16:12,160 EPOCH 26 done: loss 9.5010 - lr 0.0250000\n",
            "2021-05-10 20:16:46,720 DEV : loss 8.72773551940918 - score 0.6336\n",
            "2021-05-10 20:16:47,256 BAD EPOCHS (no improvement): 3\n",
            "2021-05-10 20:16:47,265 ----------------------------------------------------------------------------------------------------\n",
            "2021-05-10 20:17:04,806 epoch 27 - iter 78/785 - loss 9.33972615 - samples/sec: 142.40 - lr: 0.025000\n",
            "2021-05-10 20:17:22,196 epoch 27 - iter 156/785 - loss 9.55258237 - samples/sec: 143.59 - lr: 0.025000\n",
            "2021-05-10 20:17:39,544 epoch 27 - iter 234/785 - loss 9.47794609 - samples/sec: 143.94 - lr: 0.025000\n",
            "2021-05-10 20:17:57,053 epoch 27 - iter 312/785 - loss 9.47227360 - samples/sec: 142.63 - lr: 0.025000\n",
            "2021-05-10 20:18:13,996 epoch 27 - iter 390/785 - loss 9.46601641 - samples/sec: 147.40 - lr: 0.025000\n",
            "2021-05-10 20:18:31,253 epoch 27 - iter 468/785 - loss 9.51084828 - samples/sec: 144.70 - lr: 0.025000\n",
            "2021-05-10 20:18:48,693 epoch 27 - iter 546/785 - loss 9.49001480 - samples/sec: 143.18 - lr: 0.025000\n",
            "2021-05-10 20:19:06,155 epoch 27 - iter 624/785 - loss 9.49516659 - samples/sec: 143.00 - lr: 0.025000\n",
            "2021-05-10 20:19:23,072 epoch 27 - iter 702/785 - loss 9.49638185 - samples/sec: 147.62 - lr: 0.025000\n",
            "2021-05-10 20:19:39,911 epoch 27 - iter 780/785 - loss 9.49858995 - samples/sec: 148.29 - lr: 0.025000\n",
            "2021-05-10 20:19:40,861 ----------------------------------------------------------------------------------------------------\n",
            "2021-05-10 20:19:40,865 EPOCH 27 done: loss 9.4962 - lr 0.0250000\n",
            "2021-05-10 20:20:12,530 DEV : loss 8.653458595275879 - score 0.6382\n",
            "Epoch    27: reducing learning rate of group 0 to 1.2500e-02.\n",
            "2021-05-10 20:20:13,037 BAD EPOCHS (no improvement): 4\n",
            "2021-05-10 20:20:13,045 ----------------------------------------------------------------------------------------------------\n",
            "2021-05-10 20:20:30,390 epoch 28 - iter 78/785 - loss 9.38937922 - samples/sec: 143.99 - lr: 0.012500\n",
            "2021-05-10 20:20:47,351 epoch 28 - iter 156/785 - loss 9.40600305 - samples/sec: 147.23 - lr: 0.012500\n",
            "2021-05-10 20:21:04,449 epoch 28 - iter 234/785 - loss 9.45694211 - samples/sec: 146.05 - lr: 0.012500\n",
            "2021-05-10 20:21:21,676 epoch 28 - iter 312/785 - loss 9.42857727 - samples/sec: 144.95 - lr: 0.012500\n",
            "2021-05-10 20:21:38,814 epoch 28 - iter 390/785 - loss 9.43293616 - samples/sec: 145.72 - lr: 0.012500\n",
            "2021-05-10 20:21:55,672 epoch 28 - iter 468/785 - loss 9.43414888 - samples/sec: 148.13 - lr: 0.012500\n",
            "2021-05-10 20:22:12,953 epoch 28 - iter 546/785 - loss 9.42053829 - samples/sec: 144.51 - lr: 0.012500\n",
            "2021-05-10 20:22:30,317 epoch 28 - iter 624/785 - loss 9.42565539 - samples/sec: 143.85 - lr: 0.012500\n",
            "2021-05-10 20:22:47,621 epoch 28 - iter 702/785 - loss 9.43259611 - samples/sec: 144.33 - lr: 0.012500\n",
            "2021-05-10 20:23:05,000 epoch 28 - iter 780/785 - loss 9.44767036 - samples/sec: 143.69 - lr: 0.012500\n",
            "2021-05-10 20:23:06,053 ----------------------------------------------------------------------------------------------------\n",
            "2021-05-10 20:23:06,058 EPOCH 28 done: loss 9.4439 - lr 0.0125000\n",
            "2021-05-10 20:23:37,169 DEV : loss 8.587652206420898 - score 0.6515\n",
            "2021-05-10 20:23:37,679 BAD EPOCHS (no improvement): 1\n",
            "2021-05-10 20:23:37,686 ----------------------------------------------------------------------------------------------------\n",
            "2021-05-10 20:23:54,543 epoch 29 - iter 78/785 - loss 9.51404965 - samples/sec: 148.16 - lr: 0.012500\n",
            "2021-05-10 20:24:11,846 epoch 29 - iter 156/785 - loss 9.47528938 - samples/sec: 144.32 - lr: 0.012500\n",
            "2021-05-10 20:24:28,956 epoch 29 - iter 234/785 - loss 9.41066612 - samples/sec: 145.94 - lr: 0.012500\n",
            "2021-05-10 20:24:45,732 epoch 29 - iter 312/785 - loss 9.46034751 - samples/sec: 148.84 - lr: 0.012500\n",
            "2021-05-10 20:25:02,668 epoch 29 - iter 390/785 - loss 9.46276603 - samples/sec: 147.44 - lr: 0.012500\n",
            "2021-05-10 20:25:19,281 epoch 29 - iter 468/785 - loss 9.42707115 - samples/sec: 150.30 - lr: 0.012500\n",
            "2021-05-10 20:25:36,487 epoch 29 - iter 546/785 - loss 9.42628516 - samples/sec: 145.13 - lr: 0.012500\n",
            "2021-05-10 20:25:53,904 epoch 29 - iter 624/785 - loss 9.43896591 - samples/sec: 143.38 - lr: 0.012500\n",
            "2021-05-10 20:26:11,021 epoch 29 - iter 702/785 - loss 9.43520311 - samples/sec: 145.88 - lr: 0.012500\n",
            "2021-05-10 20:26:28,237 epoch 29 - iter 780/785 - loss 9.43471226 - samples/sec: 145.04 - lr: 0.012500\n",
            "2021-05-10 20:26:29,221 ----------------------------------------------------------------------------------------------------\n",
            "2021-05-10 20:26:29,223 EPOCH 29 done: loss 9.4402 - lr 0.0125000\n",
            "2021-05-10 20:27:00,510 DEV : loss 8.61343002319336 - score 0.6487\n",
            "2021-05-10 20:27:01,019 BAD EPOCHS (no improvement): 2\n",
            "2021-05-10 20:27:01,027 ----------------------------------------------------------------------------------------------------\n",
            "2021-05-10 20:27:17,942 epoch 30 - iter 78/785 - loss 9.23561531 - samples/sec: 147.67 - lr: 0.012500\n",
            "2021-05-10 20:27:34,756 epoch 30 - iter 156/785 - loss 9.21948146 - samples/sec: 148.52 - lr: 0.012500\n",
            "2021-05-10 20:27:52,167 epoch 30 - iter 234/785 - loss 9.27994739 - samples/sec: 143.42 - lr: 0.012500\n",
            "2021-05-10 20:28:09,956 epoch 30 - iter 312/785 - loss 9.35603535 - samples/sec: 140.37 - lr: 0.012500\n",
            "2021-05-10 20:28:27,406 epoch 30 - iter 390/785 - loss 9.39409768 - samples/sec: 143.11 - lr: 0.012500\n",
            "2021-05-10 20:28:44,994 epoch 30 - iter 468/785 - loss 9.40323292 - samples/sec: 141.98 - lr: 0.012500\n",
            "2021-05-10 20:29:02,378 epoch 30 - iter 546/785 - loss 9.38345958 - samples/sec: 143.67 - lr: 0.012500\n",
            "2021-05-10 20:29:19,953 epoch 30 - iter 624/785 - loss 9.41587808 - samples/sec: 142.08 - lr: 0.012500\n",
            "2021-05-10 20:29:37,601 epoch 30 - iter 702/785 - loss 9.44279667 - samples/sec: 141.50 - lr: 0.012500\n",
            "2021-05-10 20:29:54,398 epoch 30 - iter 780/785 - loss 9.41761386 - samples/sec: 148.68 - lr: 0.012500\n",
            "2021-05-10 20:29:55,398 ----------------------------------------------------------------------------------------------------\n",
            "2021-05-10 20:29:55,401 EPOCH 30 done: loss 9.4203 - lr 0.0125000\n",
            "2021-05-10 20:30:29,472 DEV : loss 8.603944778442383 - score 0.6435\n",
            "2021-05-10 20:30:29,988 BAD EPOCHS (no improvement): 3\n",
            "2021-05-10 20:30:49,273 ----------------------------------------------------------------------------------------------------\n",
            "2021-05-10 20:30:49,321 Testing using best model ...\n",
            "2021-05-10 20:30:49,338 loading file /content/drive/MyDrive/medNer/best-model.pt\n",
            "2021-05-10 20:31:32,223 0.6212\t0.6845\t0.6513\n",
            "2021-05-10 20:31:32,225 \n",
            "Results:\n",
            "- F1-score (micro) 0.6513\n",
            "- F1-score (macro) 0.6513\n",
            "\n",
            "By class:\n",
            "MED        tp: 45786 - fp: 27924 - fn: 21100 - precision: 0.6212 - recall: 0.6845 - f1-score: 0.6513\n",
            "2021-05-10 20:31:32,228 ----------------------------------------------------------------------------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'dev_loss_history': [11.548288345336914,\n",
              "  10.159350395202637,\n",
              "  9.999064445495605,\n",
              "  9.739221572875977,\n",
              "  9.728472709655762,\n",
              "  9.657806396484375,\n",
              "  9.380733489990234,\n",
              "  9.389243125915527,\n",
              "  9.286066055297852,\n",
              "  9.221763610839844,\n",
              "  9.022771835327148,\n",
              "  9.197613716125488,\n",
              "  9.324247360229492,\n",
              "  9.018321990966797,\n",
              "  8.882484436035156,\n",
              "  8.902117729187012,\n",
              "  8.950234413146973,\n",
              "  8.889472007751465,\n",
              "  8.864509582519531,\n",
              "  8.786365509033203,\n",
              "  8.770769119262695,\n",
              "  8.796380043029785,\n",
              "  8.788394927978516,\n",
              "  8.691374778747559,\n",
              "  8.662339210510254,\n",
              "  8.72773551940918,\n",
              "  8.653458595275879,\n",
              "  8.587652206420898,\n",
              "  8.61343002319336,\n",
              "  8.603944778442383],\n",
              " 'dev_score_history': [0.5485646790829133,\n",
              "  0.557079552648238,\n",
              "  0.5949591655706115,\n",
              "  0.5584639925943681,\n",
              "  0.6108539229736117,\n",
              "  0.5638420470848327,\n",
              "  0.5966312549091168,\n",
              "  0.6228635218512876,\n",
              "  0.6189455970457396,\n",
              "  0.6087094875180984,\n",
              "  0.632810155452854,\n",
              "  0.5945353075905674,\n",
              "  0.6144776835706287,\n",
              "  0.6311608263896815,\n",
              "  0.6250910725635184,\n",
              "  0.6475537413367791,\n",
              "  0.6443884648644584,\n",
              "  0.6021942365149228,\n",
              "  0.6556968091103845,\n",
              "  0.611361813864998,\n",
              "  0.6372031562653377,\n",
              "  0.6463527239150507,\n",
              "  0.6348674515643663,\n",
              "  0.649198250187533,\n",
              "  0.6424934844536032,\n",
              "  0.63363616496519,\n",
              "  0.6381759800411191,\n",
              "  0.6515337423312882,\n",
              "  0.6486822774563007,\n",
              "  0.6434961048831466],\n",
              " 'test_score': 0.6513129818771516,\n",
              " 'train_loss_history': [13.492970956814517,\n",
              "  11.866202845239336,\n",
              "  11.420654713576008,\n",
              "  11.198994258103097,\n",
              "  10.965802450240798,\n",
              "  10.812801029424,\n",
              "  10.675314417918017,\n",
              "  10.548740413082633,\n",
              "  10.458672043016762,\n",
              "  10.390139139381944,\n",
              "  10.295403877792845,\n",
              "  10.212782372638678,\n",
              "  10.18424473234043,\n",
              "  10.123857161042038,\n",
              "  10.082108897919868,\n",
              "  9.841320265630248,\n",
              "  9.794989876230812,\n",
              "  9.744636192443265,\n",
              "  9.72511753398142,\n",
              "  9.703490057416783,\n",
              "  9.699192082957858,\n",
              "  9.678201597055812,\n",
              "  9.650074780822559,\n",
              "  9.567185281644202,\n",
              "  9.517245328502291,\n",
              "  9.500959757179212,\n",
              "  9.496193900381684,\n",
              "  9.443897948295447,\n",
              "  9.440245915674101,\n",
              "  9.42029723331427]}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dYnexEofYOud"
      },
      "source": [
        "LOAD MODEL"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6nFmuF-iYL2p",
        "outputId": "09ed1ff6-f452-4674-a084-31026cc52d37"
      },
      "source": [
        "from flair.data import Sentence\n",
        "from flair.models import SequenceTagger\n",
        "# load the trained model\n",
        "model = SequenceTagger.load('/content/drive/MyDrive/medNer/trainedFlair/final-model.pt')\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-05-12 12:31:09,724 loading file /content/drive/MyDrive/medNer/trainedFlair/final-model.pt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eN8wqBwmYcMQ"
      },
      "source": [
        "RESULTS"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z-W5UteMYYGh",
        "outputId": "bc1353ba-d9ae-49eb-9bf3-793ee1812930"
      },
      "source": [
        "from segtok.segmenter import split_single\n",
        "#read file\n",
        "Text=\"/content/drive/MyDrive/medNer/paper.txt\"\n",
        "with open(Text, \"r\") as file1:\n",
        "    FileasList = file1.readlines()\n",
        "TextStr= FileasList[0]\n",
        "\n",
        "#NER\n",
        "#2.Whole text predict\n",
        "TextStrAll=Sentence(TextStr)\n",
        "model.predict(TextStrAll)\n",
        "print(TextStrAll.to_tagged_string())"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The purpose of this study <B-MED> was to evaluate the effect <B-MED> of femoral <B-MED> tunnel <I-MED> orientation <B-MED> , drilled <B-MED> through the accessory <B-MED> anteromedial <I-MED> ( AAM <B-MED> ) portal <B-MED> or the high AM <B-MED> portal <I-MED> in anatomic <B-MED> anterior <I-MED> cruciate <I-MED> ligament <I-MED> ( ACL <B-MED> ) reconstruction <B-MED> . In 16 cadaver <B-MED> knees <I-MED> , using o'clock <B-MED> method <I-MED> , centers <B-MED> of the ACL <B-MED> femoral <I-MED> footprint <I-MED> were drilled with an 8-mm <B-MED> reamer <B-MED> via an AAM <B-MED> portal <I-MED> ( eight knees <B-MED> ) or a high AM <B-MED> portal <I-MED> ( eight knees <B-MED> ) . Computed <B-MED> tomography <I-MED> ( CT <B-MED> ) scans <B-MED> were taken of each knee <B-MED> . Three-dimensional <B-MED> ( 3D <B-MED> ) models <B-MED> were constructed to identify the femoral <B-MED> tunnel <I-MED> orientation <B-MED> and to create femoral <B-MED> tunnel <I-MED> virtual <I-MED> cylinders <I-MED> for measuring <B-MED> tunnel <I-MED> angles <I-MED> and length <B-MED> . In two of the 16 specimens <B-MED> , we observed a posterior <B-MED> femoral <I-MED> cortex <I-MED> blowout <B-MED> ( PFCB <B-MED> ) when drilling <B-MED> through a high AM <B-MED> portal <I-MED> . When drilled <B-MED> through the high <B-MED> AM <I-MED> portal <I-MED> , the femoral <B-MED> tunnel <I-MED> length <I-MED> was significantly shorter than when using an AAM <B-MED> portal <I-MED> ( 30.3 ± 3.8 mm and 38.2 ± 3.1 mm , p < 0.001 ) . The femoral <B-MED> tunnel <I-MED> length <I-MED> was significantly shorter in the group <B-MED> with PFCB <B-MED> compared to the group <B-MED> with no PFCB ( 25.9 ± 0.6 mm and 35.5 ± 4.5 mm , p = 0.011 ) . The axial <B-MED> obliquity <I-MED> of the high <B-MED> AM <I-MED> portal <I-MED> was significantly higher than that of the AAM <B-MED> portal <I-MED> ( 52.2 ± 5.9 ° and 43.0 ± 2.3 ° , p = 0.003 ) . In anatomic <B-MED> ACL <I-MED> reconstruction <I-MED> , a mal-positioned <B-MED> AM <I-MED> portal <I-MED> can cause abnormal <B-MED> tunnel <I-MED> orientation <B-MED> , which may lead to mechanical <B-MED> failure <I-MED> during ACL <B-MED> reconstruction <I-MED> . Therefore , it is important to select accurate <B-MED> AM <B-MED> portal <I-MED> positioning <I-MED> , and possibly using an AAM <B-MED> portal <I-MED> by measuring <B-MED> an accurate <B-MED> position <I-MED> when drilling a femoral <B-MED> tunnel <I-MED> in anatomic <B-MED> ACL <I-MED> reconstruction <I-MED> .\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cjX18imTj46i"
      },
      "source": [
        "28366539|t|Influence of the different anteromedial portal on femoral tunnel orientation during anatomic ACL reconstruction\n",
        "28366539|a|The purpose of this study was to evaluate the effect of femoral tunnel orientation, drilled through the accessory anteromedial (AAM) portal or the high AM portal in anatomic anterior cruciate ligament (ACL) reconstruction. In 16 cadaver knees, using o'clock method, centers of the ACL femoral footprint were drilled with an 8-mm reamer via an AAM portal (eight knees) or a high AM portal (eight knees). Computed tomography (CT) scans were taken of each knee. Three-dimensional (3D) models were constructed to identify the femoral tunnel orientation and to create femoral tunnel virtual cylinders for measuring tunnel angles and length. In two of the 16 specimens, we observed a posterior femoral cortex blowout (PFCB) when drilling through a high AM portal. When drilled through the high AM portal, the femoral tunnel length was significantly shorter than when using an AAM portal (30.3 ± 3.8 mm and 38.2 ± 3.1 mm, p < 0.001). The femoral tunnel length was significantly shorter in the group with PFCB compared to the group with no PFCB (25.9 ± 0.6 mm and 35.5 ± 4.5 mm, p = 0.011). The axial obliquity of the high AM portal was significantly higher than that of the AAM portal (52.2 ± 5.9° and 43.0 ± 2.3°, p = 0.003). In anatomic ACL reconstruction, a mal-positioned AM portal can cause abnormal tunnel orientation, which may lead to mechanical failure during ACL reconstruction. Therefore, it is important to select accurate AM portal positioning, and possibly using an AAM portal by measuring an accurate position when drilling a femoral tunnel in anatomic ACL reconstruction.\n",
        "28366539\t17\t26\tdifferent\tT080\tC1705242\n",
        "28366539\t27\t46\tanteromedial portal\tT061\tC0185154\n",
        "28366539\t50\t64\tfemoral tunnel\tT023\tC0015811\n",
        "28366539\t65\t76\torientation\tT082\tC1704322\n",
        "28366539\t84\t92\tanatomic\tT080\tC0220784\n",
        "28366539\t93\t111\tACL reconstruction\tT061\tC0188185\n",
        "28366539\t145\t153\tevaluate\tT058\tC0220825\n",
        "28366539\t158\t164\teffect\tT080\tC1280500\n",
        "28366539\t168\t182\tfemoral tunnel\tT023\tC0015811\n",
        "28366539\t183\t194\torientation\tT082\tC1704322\n",
        "28366539\t196\t203\tdrilled\tT061\tC0337279\n",
        "28366539\t216\t251\taccessory anteromedial (AAM) portal\tT061\tC0185154\n",
        "28366539\t259\t273\thigh AM portal\tT061\tC0185154\n",
        "28366539\t277\t333\tanatomic anterior cruciate ligament (ACL) reconstruction\tT061\tC0188185\n",
        "28366539\t341\t348\tcadaver\tT017\tC0006629\n",
        "28366539\t349\t354\tknees\tT023\tC0022742\n",
        "28366539\t362\t376\to'clock method\tT061\tC1293156\n",
        "28366539\t378\t385\tcenters\tT082\tC0205099\n",
        "28366539\t393\t414\tACL femoral footprint\tT023\tC0078960\n",
        "28366539\t420\t427\tdrilled\tT061\tC0337279\n",
        "28366539\t441\t447\treamer\tT074\tC3853551\n",
        "28366539\t455\t465\tAAM portal\tT061\tC0185154\n",
        "28366539\t473\t478\tknees\tT023\tC0022742\n",
        "28366539\t485\t499\thigh AM portal\tT061\tC0087111\n",
        "28366539\t507\t512\tknees\tT023\tC0022742\n",
        "28366539\t515\t545\tComputed tomography (CT) scans\tT060\tC0040405\n",
        "28366539\t565\t569\tknee\tT023\tC0022742\n",
        "28366539\t571\t600\tThree-dimensional (3D) models\tT075\tC0026336\n",
        "28366539\t634\t648\tfemoral tunnel\tT023\tC0015811\n",
        "28366539\t649\t660\torientation\tT082\tC1704322\n",
        "28366539\t668\t674\tcreate\tT052\tC1706214\n",
        "28366539\t675\t707\tfemoral tunnel virtual cylinders\tT023\tC0015811\n",
        "28366539\t712\t721\tmeasuring\tT080\tC0444706\n",
        "28366539\t722\t735\ttunnel angles\tT030\tC0229984\n",
        "28366539\t740\t746\tlength\tT081\tC1444754\n",
        "28366539\t765\t774\tspecimens\tT167\tC0370003\n",
        "28366539\t779\t787\tobserved\tT169\tC1441672\n",
        "28366539\t790\t822\tposterior femoral cortex blowout\tT046\tC0021890\n",
        "28366539\t824\t828\tPFCB\tT046\tC0021890\n",
        "28366539\t835\t843\tdrilling\tT061\tC0337279\n",
        "28366539\t844\t851\tthrough\tT169\tC0332273\n",
        "28366539\t854\t868\thigh AM portal\tT061\tC0185154\n",
        "28366539\t875\t882\tdrilled\tT061\tC0337279\n",
        "28366539\t883\t890\tthrough\tT169\tC0332273\n",
        "28366539\t895\t909\thigh AM portal\tT061\tC0185154\n",
        "28366539\t915\t929\tfemoral tunnel\tT023\tC0015811\n",
        "28366539\t930\t936\tlength\tT081\tC1444754\n",
        "28366539\t941\t954\tsignificantly\tT078\tC0750502\n",
        "28366539\t955\t962\tshorter\tT081\tC1806781\n",
        "28366539\t982\t992\tAAM portal\tT061\tC0185154\n",
        "28366539\t1043\t1057\tfemoral tunnel\tT023\tC0015811\n",
        "28366539\t1058\t1064\tlength\tT081\tC1444754\n",
        "28366539\t1069\t1082\tsignificantly\tT078\tC0750502\n",
        "28366539\t1083\t1090\tshorter\tT081\tC1806781\n",
        "28366539\t1098\t1103\tgroup\tT078\tC0441833\n",
        "28366539\t1109\t1113\tPFCB\tT046\tC0021890\n",
        "28366539\t1114\t1122\tcompared\tT052\tC1707455\n",
        "28366539\t1130\t1135\tgroup\tT078\tC0441833\n",
        "28366539\t1141\t1148\tno PFCB\tT033\tC0243095\n",
        "28366539\t1199\t1214\taxial obliquity\tT082\tC0205315\n",
        "28366539\t1222\t1236\thigh AM portal\tT061\tC0185154\n",
        "28366539\t1241\t1254\tsignificantly\tT078\tC0750502\n",
        "28366539\t1255\t1261\thigher\tT080\tC0205250\n",
        "28366539\t1279\t1289\tAAM portal\tT061\tC0185154\n",
        "28366539\t1335\t1343\tanatomic\tT080\tC0220784\n",
        "28366539\t1344\t1362\tACL reconstruction\tT061\tC0188185\n",
        "28366539\t1366\t1380\tmal-positioned\tT082\tC0333042\n",
        "28366539\t1381\t1390\tAM portal\tT061\tC0185154\n",
        "28366539\t1401\t1409\tabnormal\tT033\tC0205161\n",
        "28366539\t1410\t1416\ttunnel\tT023\tC0015811\n",
        "28366539\t1417\t1428\torientation\tT082\tC1704322\n",
        "28366539\t1448\t1458\tmechanical\tT169\tC0443254\n",
        "28366539\t1474\t1492\tACL reconstruction\tT061\tC0188185\n",
        "28366539\t1531\t1539\taccurate\tT080\tC0443131\n",
        "28366539\t1540\t1549\tAM portal\tT061\tC0185154\n",
        "28366539\t1550\t1561\tpositioning\tT082\tC0733755\n",
        "28366539\t1585\t1595\tAAM portal\tT061\tC0185154\n",
        "28366539\t1599\t1608\tmeasuring\tT080\tC0444706\n",
        "28366539\t1612\t1620\taccurate\tT080\tC0443131\n",
        "28366539\t1621\t1629\tposition\tT082\tC0733755\n",
        "28366539\t1635\t1643\tdrilling\tT061\tC0337279\n",
        "28366539\t1646\t1660\tfemoral tunnel\tT023\tC0015811\n",
        "28366539\t1664\t1672\tanatomic\tT080\tC0220784\n",
        "28366539\t1673\t1691\tACL reconstruction\tT061\tC0188185"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GPCDARAFVpbc"
      },
      "source": [
        "###ATTEMPT TO TRY SCISPACY PRETRAINED MODEL FOR CURIOSITY. DO NOT RUN, IT IS NOT WORKING. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zvOmzsmcNTMO"
      },
      "source": [
        "SCISPACY: is a model for biomedical text processing\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G-27EmHcNqCk"
      },
      "source": [
        "en_core_sci_sm will be the model used: A full spaCy pipeline for biomedical data with a larger vocabulary and 50k word vectors."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7vtqB6FRNnen",
        "outputId": "e4f3b277-2a1f-4394-9a94-ada899295ae7"
      },
      "source": [
        "!pip install -U spacy\n",
        "!pip install scispacy\n",
        "!pip install https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.4.0/en_core_sci_sm-0.4.0.tar.gz"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already up-to-date: spacy in /usr/local/lib/python3.7/dist-packages (3.0.6)\n",
            "Requirement already satisfied, skipping upgrade: blis<0.8.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (0.4.1)\n",
            "Requirement already satisfied, skipping upgrade: wasabi<1.1.0,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from spacy) (0.8.2)\n",
            "Requirement already satisfied, skipping upgrade: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.19.5)\n",
            "Requirement already satisfied, skipping upgrade: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.0.5)\n",
            "Requirement already satisfied, skipping upgrade: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (20.9)\n",
            "Requirement already satisfied, skipping upgrade: typer<0.4.0,>=0.3.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (0.3.2)\n",
            "Requirement already satisfied, skipping upgrade: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy) (2.0.5)\n",
            "Requirement already satisfied, skipping upgrade: jinja2 in /usr/local/lib/python3.7/dist-packages (from spacy) (2.11.3)\n",
            "Requirement already satisfied, skipping upgrade: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy) (3.0.5)\n",
            "Requirement already satisfied, skipping upgrade: typing-extensions<4.0.0.0,>=3.7.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from spacy) (3.7.4.3)\n",
            "Requirement already satisfied, skipping upgrade: thinc<8.1.0,>=8.0.3 in /usr/local/lib/python3.7/dist-packages (from spacy) (8.0.3)\n",
            "Requirement already satisfied, skipping upgrade: srsly<3.0.0,>=2.4.1 in /usr/local/lib/python3.7/dist-packages (from spacy) (2.4.1)\n",
            "Requirement already satisfied, skipping upgrade: pathy>=0.3.5 in /usr/local/lib/python3.7/dist-packages (from spacy) (0.5.2)\n",
            "Requirement already satisfied, skipping upgrade: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (4.41.1)\n",
            "Requirement already satisfied, skipping upgrade: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy) (56.0.0)\n",
            "Requirement already satisfied, skipping upgrade: spacy-legacy<3.1.0,>=3.0.4 in /usr/local/lib/python3.7/dist-packages (from spacy) (3.0.5)\n",
            "Requirement already satisfied, skipping upgrade: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (2.23.0)\n",
            "Requirement already satisfied, skipping upgrade: catalogue<2.1.0,>=2.0.3 in /usr/local/lib/python3.7/dist-packages (from spacy) (2.0.3)\n",
            "Requirement already satisfied, skipping upgrade: pydantic<1.8.0,>=1.7.1 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.7.3)\n",
            "Requirement already satisfied, skipping upgrade: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->spacy) (2.4.7)\n",
            "Requirement already satisfied, skipping upgrade: click<7.2.0,>=7.1.1 in /usr/local/lib/python3.7/dist-packages (from typer<0.4.0,>=0.3.0->spacy) (7.1.2)\n",
            "Requirement already satisfied, skipping upgrade: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->spacy) (1.1.1)\n",
            "Requirement already satisfied, skipping upgrade: smart-open<4.0.0,>=2.2.0 in /usr/local/lib/python3.7/dist-packages (from pathy>=0.3.5->spacy) (3.0.0)\n",
            "Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (1.24.3)\n",
            "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2020.12.5)\n",
            "Requirement already satisfied, skipping upgrade: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.10)\n",
            "Requirement already satisfied, skipping upgrade: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.0.4)\n",
            "Requirement already satisfied, skipping upgrade: zipp>=0.5; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from catalogue<2.1.0,>=2.0.3->spacy) (3.4.1)\n",
            "Requirement already satisfied: scispacy in /usr/local/lib/python3.7/dist-packages (0.4.0)\n",
            "Requirement already satisfied: nmslib>=1.7.3.6 in /usr/local/lib/python3.7/dist-packages (from scispacy) (2.1.1)\n",
            "Requirement already satisfied: conllu in /usr/local/lib/python3.7/dist-packages (from scispacy) (4.4)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from scispacy) (1.0.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from scispacy) (1.19.5)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scispacy) (2.23.0)\n",
            "Requirement already satisfied: spacy<3.1.0,>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from scispacy) (3.0.6)\n",
            "Requirement already satisfied: pysbd in /usr/local/lib/python3.7/dist-packages (from scispacy) (0.3.4)\n",
            "Requirement already satisfied: scikit-learn>=0.20.3 in /usr/local/lib/python3.7/dist-packages (from scispacy) (0.22.2.post1)\n",
            "Requirement already satisfied: pybind11<2.6.2 in /usr/local/lib/python3.7/dist-packages (from nmslib>=1.7.3.6->scispacy) (2.6.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.7/dist-packages (from nmslib>=1.7.3.6->scispacy) (5.4.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.0.0->scispacy) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.0.0->scispacy) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.0.0->scispacy) (2020.12.5)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.0.0->scispacy) (3.0.4)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->scispacy) (2.11.3)\n",
            "Requirement already satisfied: thinc<8.1.0,>=8.0.3 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->scispacy) (8.0.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->scispacy) (56.0.0)\n",
            "Requirement already satisfied: pathy>=0.3.5 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->scispacy) (0.5.2)\n",
            "Requirement already satisfied: typing-extensions<4.0.0.0,>=3.7.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->scispacy) (3.7.4.3)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.3 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->scispacy) (2.0.3)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->scispacy) (0.4.1)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->scispacy) (3.0.5)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.1 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->scispacy) (2.4.1)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->scispacy) (4.41.1)\n",
            "Requirement already satisfied: typer<0.4.0,>=0.3.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->scispacy) (0.3.2)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->scispacy) (1.0.5)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.4 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->scispacy) (3.0.5)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->scispacy) (0.8.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->scispacy) (20.9)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->scispacy) (2.0.5)\n",
            "Requirement already satisfied: pydantic<1.8.0,>=1.7.1 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->scispacy) (1.7.3)\n",
            "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.20.3->scispacy) (1.4.1)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->spacy<3.1.0,>=3.0.0->scispacy) (1.1.1)\n",
            "Requirement already satisfied: smart-open<4.0.0,>=2.2.0 in /usr/local/lib/python3.7/dist-packages (from pathy>=0.3.5->spacy<3.1.0,>=3.0.0->scispacy) (3.0.0)\n",
            "Requirement already satisfied: zipp>=0.5; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from catalogue<2.1.0,>=2.0.3->spacy<3.1.0,>=3.0.0->scispacy) (3.4.1)\n",
            "Requirement already satisfied: click<7.2.0,>=7.1.1 in /usr/local/lib/python3.7/dist-packages (from typer<0.4.0,>=0.3.0->spacy<3.1.0,>=3.0.0->scispacy) (7.1.2)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->spacy<3.1.0,>=3.0.0->scispacy) (2.4.7)\n",
            "Collecting https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.4.0/en_core_sci_sm-0.4.0.tar.gz\n",
            "\u001b[?25l  Downloading https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.4.0/en_core_sci_sm-0.4.0.tar.gz (15.6MB)\n",
            "\u001b[K     |████████████████████████████████| 15.6MB 204kB/s \n",
            "\u001b[?25hRequirement already satisfied: spacy<3.1.0,>=3.0.1 in /usr/local/lib/python3.7/dist-packages (from en-core-sci-sm==0.4.0) (3.0.6)\n",
            "Requirement already satisfied: typing-extensions<4.0.0.0,>=3.7.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.1->en-core-sci-sm==0.4.0) (3.7.4.3)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.1->en-core-sci-sm==0.4.0) (1.19.5)\n",
            "Requirement already satisfied: pydantic<1.8.0,>=1.7.1 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.1->en-core-sci-sm==0.4.0) (1.7.3)\n",
            "Requirement already satisfied: thinc<8.1.0,>=8.0.3 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.1->en-core-sci-sm==0.4.0) (8.0.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.1->en-core-sci-sm==0.4.0) (56.0.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.1->en-core-sci-sm==0.4.0) (2.23.0)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.1->en-core-sci-sm==0.4.0) (0.8.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.1->en-core-sci-sm==0.4.0) (20.9)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.4 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.1->en-core-sci-sm==0.4.0) (3.0.5)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.1->en-core-sci-sm==0.4.0) (3.0.5)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.1 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.1->en-core-sci-sm==0.4.0) (2.4.1)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.1->en-core-sci-sm==0.4.0) (2.0.5)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.1->en-core-sci-sm==0.4.0) (0.4.1)\n",
            "Requirement already satisfied: typer<0.4.0,>=0.3.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.1->en-core-sci-sm==0.4.0) (0.3.2)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.1->en-core-sci-sm==0.4.0) (4.41.1)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.1->en-core-sci-sm==0.4.0) (1.0.5)\n",
            "Requirement already satisfied: pathy>=0.3.5 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.1->en-core-sci-sm==0.4.0) (0.5.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.1->en-core-sci-sm==0.4.0) (2.11.3)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.3 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.1->en-core-sci-sm==0.4.0) (2.0.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.1.0,>=3.0.1->en-core-sci-sm==0.4.0) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.1.0,>=3.0.1->en-core-sci-sm==0.4.0) (2020.12.5)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.1.0,>=3.0.1->en-core-sci-sm==0.4.0) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.1.0,>=3.0.1->en-core-sci-sm==0.4.0) (3.0.4)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->spacy<3.1.0,>=3.0.1->en-core-sci-sm==0.4.0) (2.4.7)\n",
            "Requirement already satisfied: click<7.2.0,>=7.1.1 in /usr/local/lib/python3.7/dist-packages (from typer<0.4.0,>=0.3.0->spacy<3.1.0,>=3.0.1->en-core-sci-sm==0.4.0) (7.1.2)\n",
            "Requirement already satisfied: smart-open<4.0.0,>=2.2.0 in /usr/local/lib/python3.7/dist-packages (from pathy>=0.3.5->spacy<3.1.0,>=3.0.1->en-core-sci-sm==0.4.0) (3.0.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->spacy<3.1.0,>=3.0.1->en-core-sci-sm==0.4.0) (1.1.1)\n",
            "Requirement already satisfied: zipp>=0.5; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from catalogue<2.1.0,>=2.0.3->spacy<3.1.0,>=3.0.1->en-core-sci-sm==0.4.0) (3.4.1)\n",
            "Building wheels for collected packages: en-core-sci-sm\n",
            "  Building wheel for en-core-sci-sm (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for en-core-sci-sm: filename=en_core_sci_sm-0.4.0-cp37-none-any.whl size=15660355 sha256=2e78c1cafacc20bce102d1467b8fef09d76daee83f459236a92947b854c1d2ea\n",
            "  Stored in directory: /root/.cache/pip/wheels/f9/f0/40/7b2fce8bf7438ab151361245b1e91d4dc78e690189e8d83271\n",
            "Successfully built en-core-sci-sm\n",
            "Installing collected packages: en-core-sci-sm\n",
            "Successfully installed en-core-sci-sm-0.4.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m6_XQbAuL2aW"
      },
      "source": [
        "import scispacy\n",
        "import spacy\n",
        "#import en_core_sci_sm   #The model we are going to use\n",
        "from spacy import displacy\n",
        "from scispacy.abbreviation import AbbreviationDetector\n",
        "from scispacy.umls_linking import UmlsEntityLinker\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GHO2fd9wL5ko"
      },
      "source": [
        "nlp = spacy.load(\"en_core_sci_sm\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_NziZHwxMVhf"
      },
      "source": [
        "Example medical text"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uiB2EjV3MUWk"
      },
      "source": [
        "Text=\"/content/drive/MyDrive/medNer/paper1.txt\"\n",
        "with open(Text, \"r\") as file1:\n",
        "    FileasList = file1.readlines()\n",
        "text= str(FileasList[1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 545
        },
        "id": "2HGyY9oAMJEG",
        "outputId": "8aaef7e7-5bc1-4793-b6e7-f14d5d615ff9"
      },
      "source": [
        "doc = nlp(text)\n",
        "\n",
        "print(list(doc.sents))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/spacy_legacy/layers/staticvectors_v1.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(model, docs, is_train)\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m         \u001b[0mvectors_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgemm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_contig\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mV\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrows\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mW\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrans2\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/thinc/backends/numpy_ops.pyx\u001b[0m in \u001b[0;36mthinc.backends.numpy_ops.NumpyOps.gemm\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpy.pyx\u001b[0m in \u001b[0;36mblis.py.gemm\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Buffer and memoryview are not contiguous in the same dimension.",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-31-5e87c5c96a94>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdoc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnlp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msents\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/spacy/language.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, text, disable, component_cfg)\u001b[0m\n\u001b[1;32m    998\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mErrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mE109\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    999\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1000\u001b[0;31m                 \u001b[0merror_handler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1001\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdoc\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1002\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mErrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mE005\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/spacy/util.py\u001b[0m in \u001b[0;36mraise_error\u001b[0;34m(proc_name, proc, docs, e)\u001b[0m\n\u001b[1;32m   1501\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1502\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mraise_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproc_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdocs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1503\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1504\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1505\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/spacy/language.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, text, disable, component_cfg)\u001b[0m\n\u001b[1;32m    993\u001b[0m                 \u001b[0merror_handler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mproc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_error_handler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    994\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 995\u001b[0;31m                 \u001b[0mdoc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mproc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcomponent_cfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    996\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    997\u001b[0m                 \u001b[0;31m# This typically happens if a component is not initialized\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/spacy/pipeline/trainable_pipe.pyx\u001b[0m in \u001b[0;36mspacy.pipeline.trainable_pipe.TrainablePipe.__call__\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/spacy/util.py\u001b[0m in \u001b[0;36mraise_error\u001b[0;34m(proc_name, proc, docs, e)\u001b[0m\n\u001b[1;32m   1501\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1502\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mraise_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproc_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdocs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1503\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1504\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1505\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/spacy/pipeline/trainable_pipe.pyx\u001b[0m in \u001b[0;36mspacy.pipeline.trainable_pipe.TrainablePipe.__call__\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/spacy/pipeline/tok2vec.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, docs)\u001b[0m\n\u001b[1;32m    119\u001b[0m         \u001b[0mDOCS\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mhttps\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0mspacy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mapi\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mtok2vec\u001b[0m\u001b[0;31m#predict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m         \"\"\"\n\u001b[0;32m--> 121\u001b[0;31m         \u001b[0mtokvecs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdocs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    122\u001b[0m         \u001b[0mbatch_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTok2VecListener\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_batch_id\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdocs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mlistener\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlisteners\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/thinc/model.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    310\u001b[0m         \u001b[0monly\u001b[0m \u001b[0mthe\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minstead\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    311\u001b[0m         \"\"\"\n\u001b[0;32m--> 312\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_train\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    313\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    314\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfinish_update\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptimizer\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/thinc/layers/chain.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(model, X, is_train)\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mcallbacks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m         \u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minc_layer_grad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_train\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mis_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m         \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minc_layer_grad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/thinc/model.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, X, is_train)\u001b[0m\n\u001b[1;32m    286\u001b[0m         \"\"\"Call the model's `forward` function, returning the output and a\n\u001b[1;32m    287\u001b[0m         callback to compute the gradients via backpropagation.\"\"\"\n\u001b[0;32m--> 288\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_train\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mis_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    289\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    290\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minitialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mInT\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mOutT\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;34m\"Model\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/thinc/layers/chain.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(model, X, is_train)\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mcallbacks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m         \u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minc_layer_grad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_train\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mis_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m         \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minc_layer_grad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/thinc/model.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, X, is_train)\u001b[0m\n\u001b[1;32m    286\u001b[0m         \"\"\"Call the model's `forward` function, returning the output and a\n\u001b[1;32m    287\u001b[0m         callback to compute the gradients via backpropagation.\"\"\"\n\u001b[0;32m--> 288\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_train\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mis_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    289\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    290\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minitialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mInT\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mOutT\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;34m\"Model\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/thinc/layers/concatenate.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(model, X, is_train)\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mInT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mOutT\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mInT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_train\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mOutT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCallable\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m     \u001b[0mYs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_train\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mis_train\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mYs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_list_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mYs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_train\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/thinc/layers/concatenate.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mInT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mOutT\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mInT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_train\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mOutT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCallable\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m     \u001b[0mYs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_train\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mis_train\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mYs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_list_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mYs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_train\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/thinc/model.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, X, is_train)\u001b[0m\n\u001b[1;32m    286\u001b[0m         \"\"\"Call the model's `forward` function, returning the output and a\n\u001b[1;32m    287\u001b[0m         callback to compute the gradients via backpropagation.\"\"\"\n\u001b[0;32m--> 288\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_train\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mis_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    289\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    290\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minitialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mInT\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mOutT\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;34m\"Model\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/spacy_legacy/layers/staticvectors_v1.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(model, docs, is_train)\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0mvectors_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgemm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_contig\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mV\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrows\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mW\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrans2\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mErrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mE896\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m     output = Ragged(\n\u001b[1;32m     49\u001b[0m         \u001b[0mvectors_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mdoc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdocs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"i\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: [E896] There was an error using the static vectors. Ensure that the vectors of the vocab are properly initialized, or set 'include_static_vectors' to False."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        },
        "id": "jr75vb5yMlGG",
        "outputId": "dee90d78-cb01-4926-e5c4-b03dbb17655e"
      },
      "source": [
        "#mi intento\n",
        "print(list(doc.sents,doc.ents))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-32-8c848935600b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#mi intento\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msents\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ments\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'doc' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UG2BDKdTNCh1"
      },
      "source": [
        "displacy.serve(doc, style=\"ent\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dZvf7_3rPf8O"
      },
      "source": [
        "Extra: Abreviation definition"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j1xjvfxZPi_F"
      },
      "source": [
        "# Add the abbreviation pipe to the spacy pipeline.\n",
        "abbreviation_pipe = AbbreviationDetector(nlp)\n",
        "nlp.add_pipe(abbreviation_pipe)\n",
        "#Print the Abbreviation and it's definition\n",
        "print(\"Abbreviation\", \"\\t\", \"Definition\")\n",
        "for abrv in doc._.abbreviations:\n",
        "      print(f\"{abrv} \\t ({abrv.start}, {abrv.end}) {abrv._.long_form}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vRYPjj5xPj18"
      },
      "source": [
        "Extra: CUI UMLS LINKAGE"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SQL_XWlFPnAB"
      },
      "source": [
        "from scispacy.umls_linking import UmlsEntityLinker\n",
        "\n",
        "nlp = spacy.load(\"en_core_sci_sm\")\n",
        "linker = UmlsEntityLinker(resolve_abbreviations=True)\n",
        "\n",
        "nlp.add_pipe(linker)\n",
        "# Each entity is linked to UMLS with a score\n",
        "# (currently just char-3gram matching).\n",
        "for umls_ent in entity._.umls_ents:\n",
        "          print(linker.umls.cui_to_entity[umls_ent[0]])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c0gA2NRnOGWp"
      },
      "source": [
        "OTHER INTERESTING MODEL OPTIONS WITH SCISPACY:\n",
        "\n",
        "-en_ner_bionlp13cg_md which has the following entities:\n",
        "\n",
        "AMINO_ACID, ANATOMICAL_SYSTEM, CANCER, CELL, CELLULAR_COMPONENT, DEVELOPING_ANATOMICAL_STRUCTURE, GENE_OR_GENE_PRODUCT, IMMATERIAL_ANATOMICAL_ENTITY, MULTI-TISSUE_STRUCTURE, ORGAN, ORGANISM, ORGANISM_SUBDIVISION, ORGANISM_SUBSTANCE, PATHOLOGICAL_FORMATION, SIMPLE_CHEMICAL, TISSUE\n",
        "\n",
        "-en_ner_jnlpba_md which has the following entities:\n",
        "\n",
        "DNA, CELL_TYPE, CELL_LINE, RNA, PROTEIN"
      ]
    }
  ]
}